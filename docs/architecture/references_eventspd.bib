% =============================================================================
% EventSPD References
% =============================================================================

% --- Core Methods -----------------------------------------------------------

@article{das2025f3,
  title     = {Fast Feature Fields ({F}$^3$): A Predictive Representation of Events},
  author    = {Das, Richeek and Daniilidis, Kostas and Chaudhari, Pratik},
  journal   = {arXiv preprint arXiv:2509.25146},
  year      = {2025},
}

@inproceedings{zhu2021deformable,
  title     = {Deformable {DETR}: Deformable Transformers for End-to-End Object Detection},
  author    = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021},
  note      = {Oral},
}

@inproceedings{carion2020detr,
  title     = {End-to-End Object Detection with Transformers},
  author    = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2020},
}

@inproceedings{kirillov2023sam,
  title     = {Segment Anything},
  author    = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2023},
}

@article{ravi2024sam2,
  title     = {{SAM} 2: Segment Anything in Images and Videos},
  author    = {Ravi, Nikhila and Gabber, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal   = {arXiv preprint arXiv:2408.00714},
  year      = {2024},
}

@inproceedings{jaegle2022perceiverio,
  title     = {Perceiver {IO}: A General Architecture for Structured Inputs \& Outputs},
  author    = {Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and H{\'e}naff, Olivier and Botvinick, Matthew M. and Zisserman, Andrew and Vinyals, Oriol and Carreira, Jo{\~a}o},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2022},
}

@inproceedings{chen2021liif,
  title     = {Learning Continuous Image Representation with Local Implicit Image Function},
  author    = {Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021},
  note      = {Oral},
}

@inproceedings{kirillov2020pointrend,
  title     = {{PointRend}: Image Segmentation as Rendering},
  author    = {Kirillov, Alexander and Wu, Yuxin and He, Kaiming and Girshick, Ross},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2020},
}

% --- Depth Estimation -------------------------------------------------------

@inproceedings{yang2024dav2,
  title     = {Depth Anything {V2}},
  author    = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Zhao, Zhen and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
}

@inproceedings{ranftl2021dpt,
  title     = {Vision Transformers for Dense Prediction},
  author    = {Ranftl, Ren{\'e} and Bochkovskiy, Alexey and Koltun, Vladlen},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2021},
}

@article{ranftl2020midas,
  title     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer},
  author    = {Ranftl, Ren{\'e} and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume    = {44},
  number    = {3},
  pages     = {1623--1637},
  year      = {2022},
}

@article{lee2019bts,
  title     = {From Big to Small: Multi-Scale Local Planar Guidance for Monocular Depth Estimation},
  author    = {Lee, Jin Han and Han, Myung-Kyu and Ko, Dong Wook and Suh, Il Hong},
  journal   = {arXiv preprint arXiv:1907.10326},
  year      = {2019},
}

@article{bhat2023zoedepth,
  title     = {{ZoeDepth}: Zero-Shot Transfer by Combining Relative and Metric Depth},
  author    = {Bhat, Shariq Farooq and Birkl, Reiner and Wofk, Diana and Wonka, Peter and M{\"u}ller, Matthias},
  journal   = {arXiv preprint arXiv:2302.12288},
  year      = {2023},
}

@article{hu2024metric3d,
  title     = {{Metric3D} v2: A Versatile Monocular Geometric Foundation Model for Zero-Shot Metric Depth and Surface Normal Estimation},
  author    = {Hu, Mu and Yin, Wei and Zhang, Chi and Cai, Zhipeng and Long, Xiaoxiao and Wang, Kaixuan and Chen, Hao and Yu, Gang and Shen, Chunhua and Shen, Shaojie},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume    = {46},
  number    = {12},
  pages     = {10579--10596},
  year      = {2024},
}

@inproceedings{ke2024marigold,
  title     = {Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
  author    = {Ke, Bingxin and Obukhov, Anton and Huang, Shengyu and Mez, Nando and Dauber, Patrick and Schindler, Konrad},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024},
}

@inproceedings{piccinelli2024unidepth,
  title     = {{UniDepth}: Universal Monocular Metric Depth Estimation},
  author    = {Piccinelli, Luigi and Yang, Yung-Hsu and Sakaridis, Christos and Segu, Mattia and Li, Siyuan and Van Gool, Luc and Yu, Fisher},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024},
}

@article{infinidepth2026,
  title     = {{InfiniDepth}: Continuous Depth Estimation at Arbitrary Resolution},
  author    = {{InfiniDepth Authors}},
  journal   = {arXiv preprint arXiv:2601.03252},
  year      = {2026},
}

@inproceedings{godard2019monodepth2,
  title     = {Digging Into Self-Supervised Monocular Depth Estimation},
  author    = {Godard, Cl{\'e}ment and {Mac Aodha}, Oisin and Firman, Michael and Brostow, Gabriel},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2019},
}

@inproceedings{watson2021manydepth,
  title     = {The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth},
  author    = {Watson, Jamie and Aodha, Oisin Mac and Prisacariu, Victor and Brostow, Gabriel and Firman, Michael},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2021},
}

% --- Event Camera Depth -----------------------------------------------------

@inproceedings{hidalgo2020e2depth,
  title     = {Learning Monocular Dense Depth from Events},
  author    = {Hidalgo-Carri{\'o}, Javier and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle = {International Conference on 3D Vision (3DV)},
  year      = {2020},
}

@inproceedings{bartolomei2025depthanyevent,
  title     = {Depth {AnyEvent}: A Cross-Modal Distillation Paradigm for Event-Based Monocular Depth Estimation},
  author    = {Bartolomei, Luca and Mannocci, Enrico and Tosi, Fabio and Poggi, Matteo and Mattoccia, Stefano},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2025},
}

@inproceedings{zhu2018evflownet,
  title     = {{EV-FlowNet}: Self-Supervised Optical Flow Estimation for Event-Based Cameras},
  author    = {Zhu, Alex Zihao and Yuan, Liangzhe and Chaney, Kenneth and Daniilidis, Kostas},
  booktitle = {Robotics: Science and Systems (RSS)},
  year      = {2018},
}

@article{gallego2020survey,
  title     = {Event-Based Vision: A Survey},
  author    = {Gallego, Guillermo and Delbr{\"u}ck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J. and Conradt, J{\"o}rg and Daniilidis, Kostas and Scaramuzza, Davide},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume    = {44},
  number    = {1},
  pages     = {154--180},
  year      = {2022},
}

% --- Architecture -----------------------------------------------------------

@inproceedings{liu2021swin,
  title     = {Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows},
  author    = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2021},
}

@inproceedings{liu2022convnext,
  title     = {A {ConvNet} for the 2020s},
  author    = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022},
}

@inproceedings{woo2023convnextv2,
  title     = {{ConvNeXt} {V2}: Co-Designing and Scaling {ConvNets} with Masked Autoencoders},
  author    = {Woo, Sanghyun and Debnath, Shoubhik and Hu, Ronghang and Chen, Xinlei and Liu, Zhuang and Kweon, In So and Xie, Saining},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2023},
}

@inproceedings{ding2024unireplknet,
  title     = {{UniRepLKNet}: A Universal Perception Large-Kernel {ConvNet} for Audio, Video, Point Cloud, Time-Series and Image Recognition},
  author    = {Ding, Xiaohan and Zhang, Yiyuan and Ge, Yixiao and Zhao, Sijie and Song, Lin and Yue, Xiangyu and Shan, Ying},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024},
}

@inproceedings{zhu2019dcnv2,
  title     = {Deformable {ConvNets} V2: More Deformable, Better Results},
  author    = {Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2019},
}

@inproceedings{liu2022dabdetr,
  title     = {{DAB-DETR}: Dynamic Anchor Boxes Are Better Queries for {DETR}},
  author    = {Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2022},
}

@inproceedings{dosovitskiy2020vit,
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021},
}

% --- Training Strategy ------------------------------------------------------

@inproceedings{zhao2017pspnet,
  title     = {Pyramid Scene Parsing Network},
  author    = {Zhao, Hengshuang and Shi, Jianping and Qi, Xiaojuan and Wang, Xiaogang and Jia, Jiaya},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2017},
}

@inproceedings{szegedy2015googlenet,
  title     = {Going Deeper with Convolutions},
  author    = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2015},
}

@inproceedings{cheng2022mask2former,
  title     = {Masked-Attention Mask Transformer for Universal Image Segmentation},
  author    = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G. and Kirillov, Alexander and Girshick, Ross},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2022},
}

@inproceedings{shrivastava2016ohem,
  title     = {Training Region-Based Object Detectors with Online Hard Example Mining},
  author    = {Shrivastava, Abhinav and Gupta, Abhinav and Girshick, Ross},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2016},
}

@inproceedings{lin2017focal,
  title     = {Focal Loss for Dense Object Detection},
  author    = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2017},
}

@inproceedings{shi2015convlstm,
  title     = {Convolutional {LSTM} Network: A Machine Learning Approach for Precipitation Nowcasting},
  author    = {Shi, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and Woo, Wang-chun},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2015},
}

% --- Datasets ---------------------------------------------------------------

@inproceedings{gehrig2021dsec,
  title     = {{DSEC}: A Stereo Event Camera Dataset for Driving Scenarios},
  author    = {Gehrig, Mathias and Aarents, Willem and Gehrig, Daniel and Scaramuzza, Davide},
  booktitle = {IEEE Robotics and Automation Letters (RA-L)},
  year      = {2021},
}

@article{zhu2018mvsec,
  title     = {The Multi Vehicle Stereo Event Camera Dataset: An Event Camera Dataset for {3D} Perception},
  author    = {Zhu, Alex Zihao and Thakur, Dinesh and {\"O}zaslan, Tolga and Pfrommer, Bernd and Kumar, Vijay and Daniilidis, Kostas},
  journal   = {IEEE Robotics and Automation Letters (RA-L)},
  volume    = {3},
  number    = {3},
  pages     = {2032--2039},
  year      = {2018},
}

@inproceedings{chaney2023m3ed,
  title     = {{M3ED}: Multi-Robot, Multi-Sensor, Multi-Environment Event Dataset},
  author    = {Chaney, Kenneth and Cladera, Fernando and Wang, Ziyun and Bisulco, Anthony and Hsieh, M. Ani and Korpela, Christopher and Kumar, Vijay and Taylor, Camillo Jose and Daniilidis, Kostas},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  year      = {2023},
}

@inproceedings{wang2020tartanair,
  title     = {{TartanAir}: A Dataset to Push the Limits of Visual {SLAM}},
  author    = {Wang, Wenshan and Zhu, Delong and Wang, Xiangwei and Hu, Yaoyu and Qiu, Yuheng and Wang, Chen and Hu, Yafei and Kapoor, Ashish and Scherer, Sebastian},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year      = {2020},
}
