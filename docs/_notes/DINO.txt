                                                         Emerging Properties in Self-Supervised Vision Transformers

                                                            Mathilde Caron1,2     Hugo Touvron1,3   Ishan Misra1   Hervé Jegou1
                                                                   Julien Mairal2    Piotr Bojanowski1    Armand Joulin1
                                                                 1
                                                                     Facebook AI Research                2
                                                                                                             Inria∗        3
                                                                                                                               Sorbonne University
arXiv:2104.14294v2 [cs.CV] 24 May 2021




                                         Figure 1: Self-attention from a Vision Transformer with 8 × 8 patches trained with no supervision. We look at the self-attention of
                                         the [CLS] token on the heads of the last layer. This token is not attached to any label nor supervision. These maps show that the model
                                         automatically learns class-specific features leading to unsupervised object segmentations.

                                                                     Abstract                                    1. Introduction
                                                                                                                     Transformers [70] have recently emerged as an alternative
                                             In this paper, we question if self-supervised learning pro-         to convolutional neural networks (convnets) for visual recog-
                                         vides new properties to Vision Transformer (ViT) [19] that              nition [19, 69, 83]. Their adoption has been coupled with
                                         stand out compared to convolutional networks (convnets).                a training strategy inspired by natural language processing
                                         Beyond the fact that adapting self-supervised methods to this           (NLP), that is, pretraining on large quantities of data and
                                         architecture works particularly well, we make the follow-               finetuning on the target dataset [18, 55]. The resulting Vision
                                         ing observations: first, self-supervised ViT features contain           Transformers (ViT) [19] are competitive with convnets but,
                                         explicit information about the semantic segmentation of an              they have not yet delivered clear benefits over them: they
                                         image, which does not emerge as clearly with supervised                 are computationally more demanding, require more training
                                         ViTs, nor with convnets. Second, these features are also ex-            data, and their features do not exhibit unique properties.
                                         cellent k-NN classifiers, reaching 78.3% top-1 on ImageNet                  In this paper, we question whether the muted success of
                                         with a small ViT. Our study also underlines the importance of           Transformers in vision can be explained by the use of super-
                                         momentum encoder [33], multi-crop training [10], and the                vision in their pretraining. Our motivation is that one of the
                                         use of small patches with ViTs. We implement our findings               main ingredients for the success of Transformers in NLP was
                                         into a simple self-supervised method, called DINO, which                the use of self-supervised pretraining, in the form of close
                                         we interpret as a form of self-distillation with no labels.             procedure in BERT [18] or language modeling in GPT [55].
                                         We show the synergy between DINO and ViTs by achieving                  These self-supervised pretraining objectives use the words
                                         80.1% top-1 on ImageNet in linear evaluation with ViT-Base.             in a sentence to create pretext tasks that provide a richer
                                                                                                                 learning signal than the supervised objective of predicting
                                                                                                                 a single label per sentence. Similarly, in images, image-
                                                                                                                 level supervision often reduces the rich visual information
                                             ∗ Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000       contained in an image to a single concept selected from a
                                         Grenoble, France.
                                         Correspondence: mathilde@fb.com                                         predefined set of a few thousand categories of objects [60].
                                         Code: https://github.com/facebookresearch/dino                              While the self-supervised pretext tasks used in NLP are


                                                                                                             1
text specific, many existing self-supervised methods have                                         loss:
shown their potential on images with convnets [10, 12, 30,                            p1       - p2 log p1       p2
33]. They typically share a similar structure but with differ-                                                        sg
ent components designed to avoid trivial solutions (collapse)                      softmax                    softmax
or to improve performance [16]. In this work, inspired from
these methods, we study the impact of self-supervised pre-                                                   centering
training on ViT features. Of particular interest, we have                                         ema
identified several interesting properties that do not emerge                     student gθs                 teacher gθt
with supervised ViTs, nor with convnets:
                                                                                      x1                         x2
   • Self-supervised ViT features explicitly contain the
     scene layout and, in particular, object boundaries, as                                        x
     shown in Figure 1. This information is directly accessi-
     ble in the self-attention modules of the last block.         Figure 2: Self-distillation with no labels. We illustrate DINO in
   • Self-supervised ViT features perform particularly well       the case of one single pair of views (x1 , x2 ) for simplicity. The
                                                                  model passes two different random transformations of an input
     with a basic nearest neighbors classifier (k-NN) without
                                                                  image to the student and teacher networks. Both networks have
     any finetuning, linear classifier nor data augmentation,     the same architecture but different parameters. The output of the
     achieving 78.3% top-1 accuracy on ImageNet.                  teacher network is centered with a mean computed over the batch.
    The emergence of segmentation masks seems to be a             Each networks outputs a K dimensional feature that is normalized
                                                                  with a temperature softmax over the feature dimension. Their
property shared across self-supervised methods. However,
                                                                  similarity is then measured with a cross-entropy loss. We apply a
the good performance with k-NN only emerge when com-
                                                                  stop-gradient (sg) operator on the teacher to propagate gradients
bining certain components such as momentum encoder [33]           only through the student. The teacher parameters are updated with
and multi-crop augmentation [10]. Another finding from our        an exponential moving average (ema) of the student parameters.
study is the importance of using smaller patches with ViTs
to improve the quality of the resulting features.                 2. Related work
    Overall, our findings about the importance of these
components lead us to design a simple self-supervised ap-         Self-supervised learning. A large body of work on self-
proach that can be interpreted as a form of knowledge             supervised learning focuses on discriminative approaches
distillation [35] with no labels. The resulting framework,        coined instance classification [12, 20, 33, 73], which con-
DINO, simplifies self-supervised training by directly pre-        siders each image a different class and trains the model
dicting the output of a teacher network—built with a mo-          by discriminating them up to data augmentations. How-
mentum encoder—by using a standard cross-entropy loss.            ever, explicitly learning a classifier to discriminate be-
Interestingly, our method can work with only a centering          tween all images [20] does not scale well with the num-
and sharpening of the teacher output to avoid collapse, while     ber of images. Wu et al. [73] propose to use a noise
other popular components such as predictor [30], advanced         contrastive estimator (NCE) [32] to compare instances in-
normalization [10] or contrastive loss [33] add little benefits   stead of classifying them. A caveat of this approach is
in terms of stability or performance. Of particular impor-        that it requires comparing features from a large number
tance, our framework is flexible and works on both convnets       of images simultaneously. In practice, this requires large
and ViTs without the need to modify the architecture, nor         batches [12] or memory banks [33, 73]. Several variants
adapt internal normalizations [58].                               allow automatic grouping of instances in the form of cluster-
    We further validate the synergy between DINO and ViT          ing [2, 8, 9, 36, 42, 74, 80, 85].
by outperforming previous self-supervised features on the            Recent works have shown that we can learn unsupervised
ImageNet linear classification benchmark with 80.1% top-1         features without discriminating between images. Of par-
accuracy with a ViT-Base with small patches. We also con-         ticular interest, Grill et al. [30] propose a metric-learning
firm that DINO works with convnets by matching the state          formulation called BYOL, where features are trained by
of the art with a ResNet-50 architecture. Finally, we discuss     matching them to representations obtained with a momentum
different scenarios to use DINO with ViTs in case of limited      encoder. Methods like BYOL work even without a momen-
computation and memory capacity. In particular, training          tum encoder, at the cost of a drop of performance [16, 30].
DINO with ViT takes just two 8-GPU servers over 3 days            Several other works echo this direction, showing that one
to achieve 76.1% on ImageNet linear benchmark, which              can match more elaborate representations [26, 27], train fea-
outperforms self-supervised systems based on convnets of          tures matching them to a uniform distribution [6] or by using
comparable sizes with significantly reduced compute require-      whitening [23, 81]. Our approach takes its inspiration from
ments [10, 30].                                                   BYOL but operates with a different similarity matching loss
and uses the exact same architecture for the student and the      Algorithm 1 DINO PyTorch pseudocode w/o multi-crop.
teacher. That way, our work completes the interpretation
                                                                  # gs, gt: student and teacher networks
initiated in BYOL of self-supervised learning as a form of        # C: center (K)
                                                                  # tps, tpt: student and teacher temperatures
Mean Teacher self-distillation [65] with no labels.               # l, m: network and center momentum rates
                                                                  gt.params = gs.params
                                                                  for x in loader: # load a minibatch x with n samples
Self-training and knowledge distillation. Self-training               x1, x2 = augment(x), augment(x) # random views
aims at improving the quality of features by propagating              s1, s2 = gs(x1), gs(x2) # student output n-by-K
                                                                      t1, t2 = gt(x1), gt(x2) # teacher output n-by-K
a small initial set of annotations to a large set of unlabeled
instances. This propagation can either be done with hard              loss = H(t1, s2)/2 + H(t2, s1)/2
                                                                      loss.backward() # back-propagate
assignments of labels [41, 78, 79] or with a soft assign-
                                                                      # student, teacher and center updates
ment [76]. When using soft labels, the approach is often              update(gs) # SGD
referred to as knowledge distillation [7, 35] and has been            gt.params = l*gt.params + (1-l)*gs.params
                                                                      C = m*C + (1-m)*cat([t1, t2]).mean(dim=0)
primarily designed to train a small network to mimic the
                                                                  def H(t, s):
output of a larger network to compress models. Xie et                 t = t.detach() # stop gradient
al. [76] have shown that distillation could be used to propa-         s = softmax(s / tps, dim=1)
                                                                      t = softmax((t - C) / tpt, dim=1) # center + sharpen
gate soft pseudo-labels to unlabelled data in a self-training         return - (t * log(s)).sum(dim=1).mean()
pipeline, drawing an essential connection between self-
training and knowledge distillation. Our work builds on
this relation and extends knowledge distillation to the case
                                                                  sharpness of the output distribution, and a similar formula
where no labels are available. Previous works have also
                                                                  holds for Pt with temperature τt . Given a fixed teacher
combined self-supervised learning and knowledge distilla-
                                                                  network gθt , we learn to match these distributions by min-
tion [25, 63, 13, 47], enabling self-supervised model com-
                                                                  imizing the cross-entropy loss w.r.t. the parameters of the
pression and performance gains. However, these works rely
                                                                  student network θs :
on a pre-trained fixed teacher while our teacher is dynam-
ically built during training. This way, knowledge distilla-
                                                                                      min H(Pt (x), Ps (x)),               (2)
tion, instead of being used as a post-processing step to self-                          θs
supervised pre-training, is directly cast as a self-supervised
objective. Finally, our work is also related to codistilla-       where H(a, b) = −a log b.
tion [1] where student and teacher have the same architecture        In the following, we detail how we adapt the problem
and use distillation during training. However, the teacher in     in Eq. (2) to self-supervised learning. First, we construct
codistillation is also distilling from the student, while it is   different distorted views, or crops, of an image with multi-
updated with an average of the student in our work.               crop strategy [10]. More precisely, from a given image, we
                                                                  generate a set V of different views. This set contains two
3. Approach                                                       global views, xg1 and xg2 and several local views of smaller
                                                                  resolution. All crops are passed through the student while
3.1. SSL with Knowledge Distillation                              only the global views are passed through the teacher, there-
   The framework used for this work, DINO, shares the same        fore encouraging “local-to-global” correspondences. We
overall structure as recent self-supervised approaches [10,       minimize the loss:
16, 12, 30, 33]. However, our method shares also similarities                      X         X
with knowledge distillation [35] and we present it under                  min                       H(Pt (x), Ps (x0 )).   (3)
                                                                           θs
this angle. We illustrate DINO in Figure 2 and propose a                        x∈{xg   g
                                                                                    1 ,x2 }   x0 ∈V
                                                                                              x0 6= x
pseudo-code implementation in Algorithm 1.
   Knowledge distillation is a learning paradigm where we            This loss is general and can be used on any number of
train a student network gθs to match the output of a given        views, even only 2. However, we follow the standard setting
teacher network gθt , parameterized by θs and θt respectively.    for multi-crop by using 2 global views at resolution 2242
Given an input image x, both networks output probability          covering a large (for example greater than 50%) area of the
distributions over K dimensions denoted by Ps and Pt . The        original image, and several local views of resolution 962
probability P is obtained by normalizing the output of the        covering only small areas (for example less than 50%) of
network g with a softmax function. More precisely,                the original image. We refer to this setting as the basic
                         exp(gθs (x)(i) /τs )                     parametrization of DINO, unless mentioned otherwise.
           Ps (x)(i) = PK                         ,        (1)       Both networks share the same architecture g with differ-
                                         (k) /τ )
                        k=1 exp(gθs (x)        s
                                                                  ent sets of parameters θs and θt . We learn the parameters θs
with τs > 0 a temperature parameter that controls the             by minimizing Eq. (3) with stochastic gradient descent.
Table 1: Networks configuration. “Blocks” is the number of          both student and teacher networks. Of particular interest, we
Transformer blocks, “dim” is channel dimension and “heads” is the   note that unlike standard convnets, ViT architectures do not
number of heads in multi-head attention. “# tokens” is the length   use batch normalizations (BN) by default. Therefore, when
of the token sequence when considering 2242 resolution inputs, “#
                                                                    applying DINO to ViT we do not use any BN also in the
params” is the total number of parameters (without counting the
projection head) and “im/s” is the inference time on a NVIDIA
                                                                    projection heads, making the system entirely BN-free.
V100 GPU with 128 samples per forward.
                                                                    Avoiding collapse. Several self-supervised methods dif-
  model        blocks dim heads #tokens #params im/s                fer by the operation used to avoid collapse, either through
                                                                    contrastive loss [73], clustering constraints [8, 10], predic-
  ResNet-50       –    2048     –       –       23M      1237       tor [30] or batch normalizations [30, 58]. While our frame-
  ViT-S/16       12    384      6      197      21M      1007       work can be stabilized with multiple normalizations [10],
  ViT-S/8        12    384      6      785      21M       180       it can also work with only a centering and sharpening of
  ViT-B/16       12    768     12      197      85M       312       the momentum teacher outputs to avoid model collapse. As
  ViT-B/8        12    768     12      785      85M        63       shown experimentally in Section 5.3, centering prevents
                                                                    one dimension to dominate but encourages collapse to the
                                                                    uniform distribution, while the sharpening has the oppo-
Teacher network. Unlike knowledge distillation, we do               site effect. Applying both operations balances their effects
not have a teacher gθt given a priori and hence, we build it        which is sufficient to avoid collapse in presence of a momen-
from past iterations of the student network. We study dif-          tum teacher. Choosing this method to avoid collapse trades
ferent update rules for the teacher in Section 5.2 and show         stability for less dependence over the batch: the centering
that freezing the teacher network over an epoch works sur-          operation only depends on first-order batch statistics and
prisingly well in our framework, while copying the student          can be interpreted as adding a bias term c to the teacher:
weight for the teacher fails to converge. Of particular in-         gt (x) ← gt (x) + c. The center c is updated with an expo-
terest, using an exponential moving average (EMA) on the            nential moving average, which allows the approach to work
student weights, i.e., a momentum encoder [33], is partic-          well across different batch sizes as shown in Section 5.5:
ularly well suited for our framework. The update rule is
                                                                                                         B
θt ← λθt + (1 − λ)θs , with λ following a cosine schedule                                            1 X
from 0.996 to 1 during training [30]. Originally the momen-                     c ← mc + (1 − m)          gθ (xi ),           (4)
                                                                                                     B i=1 t
tum encoder has been introduced as a substitute for a queue
in contrastive learning [33]. However, in our framework, its        where m > 0 is a rate parameter and B is the batch size.
role differs since we do not have a queue nor a contrastive         Output sharpening is obtained by using a low value for the
loss, and may be closer to the role of the mean teacher used        temperature τt in the teacher softmax normalization.
in self-training [65]. Indeed, we observe that this teacher per-
forms a form of model ensembling similar to Polyak-Ruppert          3.2. Implementation and evaluation protocols
averaging with an exponential decay [51, 59]. Using Polyak-            In this section, we provide the implementation details to
Ruppert averaging for model ensembling is a standard prac-          train with DINO and present the evaluation protocols used
tice to improve the performance of a model [38]. We observe         in our experiments.
that this teacher has better performance than the student
throughout the training, and hence, guides the training of the
student by providing target features of higher quality. This        Vision Transformer. We briefly describe the mechanism
dynamic was not observed in previous works [30, 58].                of the Vision Transformer (ViT) [19, 70] and refer to
                                                                    Vaswani et al. [70] for details about Transformers and to
                                                                    Dosovitskiy et al. [19] for its adaptation to images. We fol-
Network architecture. The neural network g is composed              low the implementation used in DeiT [69]. We summarize
of a backbone f (ViT [19] or ResNet [34]), and of a projec-         the configuration of the different networks used in this pa-
tion head h: g = h ◦ f . The features used in downstream            per in Table 1. The ViT architecture takes as input a grid
tasks are the backbone f output. The projection head con-           of non-overlapping contiguous image patches of resolution
sists of a 3-layer multi-layer perceptron (MLP) with hidden         N × N . In this paper we typically use N = 16 (“/16”)
dimension 2048 followed by `2 normalization and a weight            or N = 8 (“/8”). The patches are then passed through a
normalized fully connected layer [61] with K dimensions,            linear layer to form a set of embeddings. We add an extra
which is similar to the design from SwAV [10]. We have              learnable token to the sequence [18, 19]. The role of this
tested other projection heads and this particular design ap-        token is to aggregate information from the entire sequence
pears to work best for DINO (Appendix C). We do not use a           and we attach the projection head h at its output. We refer
predictor [30, 16], resulting in the exact same architecture in     to this token as the class token [CLS] for consistency with
previous works[18, 19, 69], even though it is not attached      Table 2: Linear and k-NN classification on ImageNet. We report
to any label nor supervision in our case. The set of patch      top-1 accuracy for linear and k-NN evaluations on the validation
tokens and [CLS] token are fed to a standard Transformer        set of ImageNet for different self-supervised methods. We focus
                                                                on ResNet-50 and ViT-small architectures, but also report the best
network with a “pre-norm” layer normalization [11, 39]. The
                                                                results obtained across architectures. ∗ are run by us. We run the
Transformer is a sequence of self-attention and feed-forward    k-NN evaluation for models with official released weights. The
layers, paralleled with skip connections. The self-attention    throughput (im/s) is calculated on a NVIDIA V100 GPU with 128
layers update the token representations by looking at the       samples per forward. Parameters (M) are of the feature extractor.
other token representations with an attention mechanism [4].
                                                                Method           Arch.            Param.   im/s   Linear k-NN
                                                                Supervised       RN50               23     1237    79.3     79.3
                                                                SCLR [12]        RN50               23     1237    69.1     60.7
Implementation details. We pretrain the models on the           MoCov2 [15]      RN50               23     1237    71.1     61.9
ImageNet dataset [60] without labels. We train with the         InfoMin [67]     RN50               23     1237    73.0     65.3
adamw optimizer [44] and a batch size of 1024, distributed      BarlowT [81]     RN50               23     1237    73.2     66.0
over 16 GPUs when using ViT-S/16. The learning rate is          OBoW [27]        RN50               23     1237    73.8     61.9
linearly ramped up during the first 10 epochs to its base       BYOL [30]        RN50               23     1237    74.4     64.8
value determined with the following linear scaling rule [29]:   DCv2 [10]        RN50               23     1237    75.2     67.1
lr = 0.0005 ∗ batchsize/256. After this warmup, we decay        SwAV [10]        RN50               23     1237    75.3     65.7
                                                                DINO             RN50               23     1237    75.3     67.5
the learning rate with a cosine schedule [43]. The weight
decay also follows a cosine schedule from 0.04 to 0.4. The      Supervised       ViT-S              21     1007    79.8     79.8
temperature τs is set to 0.1 while we use a linear warm-up      BYOL∗ [30]       ViT-S              21     1007    71.4     66.6
for τt from 0.04 to 0.07 during the first 30 epochs. We         MoCov2∗ [15]     ViT-S              21     1007    72.7     64.4
follow the data augmentations of BYOL [30] (color jittering,    SwAV∗ [10]       ViT-S              21     1007    73.5     66.3
                                                                DINO             ViT-S              21     1007    77.0     74.5
Gaussian blur and solarization) and multi-crop [10] with a
bicubic interpolation to adapt the position embeddings to       Comparison across architectures
the scales [19, 69]. The code and models to reproduce our       SCLR [12]      RN50w4              375      117    76.8     69.3
results is publicly available.                                  SwAV [10]      RN50w2               93      384    77.3     67.3
                                                                BYOL [30]      RN50w2               93      384    77.4      –
                                                                DINO           ViT-B/16             85      312    78.2     76.1
                                                                SwAV [10]      RN50w5              586       76    78.5     67.1
                                                                BYOL [30]      RN50w4              375      117    78.6      –
Evaluation protocols. Standard protocols for self-              BYOL [30]      RN200w2             250      123    79.6     73.9
supervised learning are to either learn a linear classifier     DINO           ViT-S/8              21      180    79.7     78.3
on frozen features [82, 33] or to finetune the features         SCLRv2 [13] RN152w3+SK             794       46    79.8     73.1
on downstream tasks. For linear evaluations, we apply           DINO           ViT-B/8              85      63     80.1     77.4
random resize crops and horizontal flips augmentation
during training, and report accuracy on a central crop.
For finetuning evaluations, we initialize networks with         4. Main Results
the pretrained weights and adapt them during training.
                                                                   We first validate the DINO framework used in this study
However, both evaluations are sensitive to hyperparameters,
                                                                with the standard self-supervised benchmark on ImageNet.
and we observe a large variance in accuracy between runs
                                                                We then study the properties of the resulting features for
when varying the learning rate for example. We thus also
                                                                retrieval, object discovery and transfer-learning.
evaluate the quality of features with a simple weighted
nearest neighbor classifier (k-NN) as in [73]. We freeze        4.1. Comparing with SSL frameworks on ImageNet
the pretrain model to compute and store the features of the
training data of the downstream task. The nearest neighbor        We consider two different settings: comparison with the
classifier then matches the feature of an image to the k        same architecture and across architectures.
nearest stored features that votes for the label. We sweep
over different number of nearest neighbors and find that        Comparing with the same architecture. In top panel of
20 NN is consistently working the best for most of our          Table 2, we compare DINO with other self-supervised meth-
runs. This evaluation protocol does not require any other       ods with the same architecture, either a ResNet-50 [34] or a
hyperparameter tuning, nor data augmentation and can be         ViT-small (which follows the design of DeiT-S [69]). The
run with only one pass over the downstream dataset, greatly     choice of ViT-S is motivated by its similarity with ResNet-50
simplifying the feature evaluation.                             along several axes: number of parameters (21M vs 23M),
Table 3: Image retrieval. We compare the performance in retrieval         Table 4: Copy detection. We report the mAP performance in copy
of off-the-shelf features pretrained with supervision or with DINO        detection on Copydays “strong” subset [21]. For reference, we
on ImageNet and Google Landmarks v2 (GLDv2) dataset. We                   also report the performance of the multigrain model [5], trained
report mAP on revisited Oxford and Paris. Pretraining with DINO           specifically for particular object retrieval.
on a landmark dataset performs particularly well. For reference, we
also report the best retrieval method with off-the-shelf features [57].   Method            Arch.         Dim.      Resolution       mAP
                                                                                                                           2
                                                                          Multigrain [5]    ResNet-50     2048         224           75.1
                                               ROx           RPar
                                                                          Multigrain [5]    ResNet-50     2048    largest side 800   82.5
Pretrain     Arch.               Pretrain    M      H      M       H
                                                                          Supervised [69]   ViT-B/16      1536         2242          76.4
Sup. [57] RN101+R-MAC             ImNet     49.8 18.5 74.0 52.1           DINO              ViT-B/16      1536         2242          81.7
                                                                          DINO              ViT-B/8       1536         3202          85.5
Sup.         ViT-S/16            ImNet      33.5 8.9 63.0 37.2
DINO         ResNet-50           ImNet      35.4 11.1 55.9 27.5
DINO         ViT-S/16            ImNet      41.8 13.7 63.1 34.4
DINO         ViT-S/16            GLDv2      51.5 24.3 75.3 51.6           4.2.1    Nearest neighbor retrieval with DINO ViT
                                                                          The results on ImageNet classification have exposed the
                                                                          potential of our features for tasks relying on nearest neighbor
throughput (1237/sec VS 1007 im/sec) and supervised per-                  retrieval. In this set of experiments, we further consolidate
formance on ImageNet with the training procedure of [69]                  this finding on landmark retrieval and copy detection tasks.
(79.3% VS 79.8%). We explore variants of ViT-S in Ap-
pendix D. First, we observe that DINO performs on par                     Image Retrieval. We consider the revisited [53] Oxford
with the state of the art on ResNet-50, validating that DINO              and Paris image retrieval datasets [50]. They contain 3 differ-
works in the standard setting. When we switch to a ViT                    ent splits of gradual difficulty with query/database pairs. We
architecture, DINO outperforms BYOL, MoCov2 and SwAV                      report the Mean Average Precision (mAP) for the Medium
by +3.5% with linear classification and by +7.9% with k-NN                (M) and Hard (H) splits. In Table 3, we compare the perfor-
evaluation. More surprisingly, the performance with a sim-                mance of different off-the-shelf features obtained with either
ple k-NN classifier is almost on par with a linear classifier             supervised or DINO training. We freeze the features and
(74.5% versus 77.0%). This property emerges only when us-                 directly apply k-NN for retrieval. We observe that DINO
ing DINO with ViT architectures, and does not appear with                 features outperform those trained on ImageNet with labels.
other existing self-supervised methods nor with a ResNet-50.                  An advantage of SSL approaches is that they can be
                                                                          trained on any dataset, without requiring any form of anno-
                                                                          tations. We train DINO on the 1.2M clean set from Google
                                                                          Landmarks v2 (GLDv2) [72], a dataset of landmarks de-
Comparing across architectures. On the bottom panel of                    signed for retrieval purposes. DINO ViT features trained on
Table 2, we compare the best performance obtained across                  GLDv2 are remarkably good, outperforming previously pub-
architectures. The interest of this setting is not to compare             lished methods based on off-the-shelf descriptors [68, 57].
methods directly, but to evaluate the limits of a ViT trained
with DINO when moving to larger architectures. While
                                                                          Copy detection. We also evaluate the performance of ViTs
training a larger ViT with DINO improves the performance,
                                                                          trained with DINO on a copy detection task. We report the
reducing the size of the patches (“/8” variants) has a bigger
                                                                          mean average precision on the “strong” subset of the INRIA
impact on the performance. While reducing the patch size
                                                                          Copydays dataset [21]. The task is to recognize images
do not add parameters, it still leads to a significant reduction
                                                                          that have been distorted by blur, insertions, print and scan,
of running time, and larger memory usage. Nonetheless, a
                                                                          etc. Following prior work [5], we add 10k distractor images
base ViT with 8 × 8 patches trained with DINO achieves
                                                                          randomly sampled from the YFCC100M dataset [66]. We
80.1% top-1 in linear classification and 77.4% with a k-NN
                                                                          perform copy detection directly with cosine similarity on the
classifier with 10× less parameters and 1.4× faster run time
                                                                          features obtained from our pretrained network. The features
than previous state of the art [13].
                                                                          are obtained as the concatenation of the output [CLS] token
                                                                          and of the GeM pooled [54] output patch tokens. This results
4.2. Properties of ViT trained with SSL                                   in a 1536d descriptor for ViT-B. Following [5], we apply
                                                                          whitening on the features. We learn this transformation on
   We evaluate properties of the DINO features in terms of                an extra 20K random images from YFCC100M, distincts
nearest neighbor search, retaining information about object               from the distractors. Table 4 shows that ViT trained with
location and transferability to downstream tasks.                         DINO is very competitive on copy detection.
Table 5: DAVIS 2017 Video object segmentation. We evaluate             Video instance segmentation. In Tab. 5, we evaluate the
the quality of frozen features on video instance tracking. We report   output patch tokens on the DAVIS-2017 video instance seg-
mean region similarity Jm and mean contour-based accuracy Fm .         mentation benchmark [52]. We follow the experimental pro-
We compare with existing self-supervised methods and a supervised
                                                                       tocol in Jabri et al. [37] and segment scenes with a nearest-
ViT-S/8 trained on ImageNet. Image resolution is 480p.
                                                                       neighbor between consecutive frames; we thus do not train
                                                                       any model on top of the features, nor finetune any weights
Method         Data         Arch.        (J &F)m       Jm      Fm
                                                                       for the task. We observe in Tab. 5 that even though our
Supervised                                                             training objective nor our architecture are designed for dense
ImageNet       INet         ViT-S/8         66.0       63.9   68.1     tasks, the performance is competitive on this benchmark.
STM [48]       I/D/Y        RN50            81.8       79.2   84.3     Since the network is not finetuned, the output of the model
Self-supervised                                                        must have retained some spatial information. Finally, for
CT [71]        VLOG         RN50            48.7       46.4   50.0     this dense recognition task, the variants with small patches
MAST [40] YT-VOS            RN18            65.5       63.3   67.6     (“/8”) perform much better (+9.1% (J &F)m for ViT-B).
STC [37]       Kinetics     RN18            67.6       64.8   70.2
DINO           INet         ViT-S/16        61.8       60.2   63.4
DINO           INet         ViT-B/16        62.3       60.7   63.9
                                                                       Probing the self-attention map. In Fig. 3, we show that
DINO           INet         ViT-S/8         69.9       66.6   73.1     different heads can attend to different semantic regions of an
DINO           INet         ViT-B/8         71.4       67.9   74.9     image, even when they are occluded (the bushes on the third
                                                                       row) or small (the flag on the second row). Visualizations are
                                                                       obtained with 480p images, resulting in sequences of 3601
                                                                       tokens for ViT-S/8. In Fig. 4, we show that a supervised
                                                                       ViT does not attend well to objects in presence of clutter
                                                                       both qualitatively and quantitatively. We report the Jaccard
                                                                       similarity between the ground truth and segmentation masks
                                                                       obtained by thresholding the self-attention map to keep 60%
                                                                       of the mass. Note that the self-attention maps are smooth
                                                                       and not optimized to produce a mask. Nonetheless, we see
                                                                       a clear difference between the supervised or DINO models
                                                                       with a significant gap in terms of Jaccard similarities. Note
                                                                       that self-supervised convnets also contain information about
                                                                       segmentations but it requires dedicated methods to extract it
                                                                       from their weights [31].

                                                                       4.2.3   Transfer learning on downstream tasks
                                                                       In Tab. 6, we evaluate the quality of the features pretrained
                                                                       with DINO on different downstream tasks. We compare
                                                                       with features from the same architectures trained with super-
                                                                       vision on ImageNet. We follow the protocol used in Tou-
                                                                       vron et al. [69] and finetune the features on each downstream
                                                                       task. We observe that for ViT architectures, self-supervised
Figure 3: Attention maps from multiple heads. We consider              pretraining transfers better than features trained with su-
the heads from the last layer of a ViT-S/8 trained with DINO and       pervision, which is consistent with observations made on
display the self-attention for [CLS] token query. Different heads,     convolutional networks [10, 33, 62]. Finally, self-supervised
materialized by different colors, focus on different locations that    pretraining greatly improves results on ImageNet (+1-2%).
represents different objects or parts (more examples in Appendix).
                                                                       5. Ablation Study of DINO
4.2.2    Discovering the semantic layout of scenes                        In this section, we empirically study DINO applied to
                                                                       ViT. The model considered for this entire study is ViT-S. We
As shown qualitatively in Figure 1, our self-attention maps            also refer the reader to Appendix for additional studies.
contain information about the segmentation of an image. In
                                                                       5.1. Importance of the Different Components
this study, we measure this property on a standard benchmark
as well as by directly probing the quality of masks generated             We show the impact of adding different components from
from these attention maps.                                             self-supervised learning on ViT trained with our framework.
Supervised                                                              Table 7: Important component for self-supervised ViT pre-
                                                                        training. Models are trained for 300 epochs with ViT-S/16. We
                                                                        study the different components that matter for the k-NN and linear
                                                                        (“Lin.”) evaluations. For the different variants, we highlight the
                                                                        differences from the default DINO setting. The best combination
                                                                        is the momentum encoder with the multicrop augmentation and
DINO
                                                                        the cross-entropy loss. We also report results with BYOL [30],
                                                                        MoCo-v2 [15] and SwAV [10].

                                                                               Method             Mom.    SK       MC        Loss    Pred. k-NN        Lin.
                                                                         1 DINO                    X       7           X      CE       7      72.8     76.1
                       Random      Supervised     DINO                   2                         7       7           X      CE       7       0.1      0.1
          ViT-S/16       22.0          27.3       45.9                   3                         X       X           X      CE       7      72.2     76.0
          ViT-S/8        21.8          23.7       44.7                   4                         X       7           7      CE       7      67.9     72.5
                                                                         5                         X       7           X     MSE       7      52.6     62.4
Figure 4: Segmentations from supervised versus DINO. We vi-              6                         X       7           X      CE       X      71.8     75.6
sualize masks obtained by thresholding the self-attention maps to
                                                                         7 BYOL                    X       7           7    MSE        X      66.6     71.4
keep 60% of the mass. On top, we show the resulting masks for
                                                                         8 MoCov2                  X       7           7    INCE       7      62.0     71.6
a ViT-S/8 trained with supervision and DINO. We show the best
                                                                         9 SwAV                    7       X           X     CE        7      64.7     71.8
head for both models. The table at the bottom compares the Jac-
card similarity between the ground truth and these masks on the               SK: Sinkhorn-Knopp, MC: Multi-Crop, Pred.: Predictor
validation images of PASCAL VOC12 dataset.                                  CE: Cross-Entropy, MSE: Mean Square Error, INCE: InfoNCE


Table 6: Transfer learning by finetuning pretrained models on
different datasets. We report top-1 accuracy. Self-supervised                                 ViT-B                    DeiT-S       Figure 5: Effect of
pretraining with DINO transfers better than supervised pretraining.                                                                 Patch Size. k-NN eval-
                                                                                       78         8x8                               uation as a function of
                                                                      ImageNet top-1




             Cifar10 Cifar100 INat18 INat19 Flwrs Cars INet                                 5x5                16x16                the throughputs for dif-
                                                                                       76                8x8                        ferent input patch sizes
 ViT-S/16                                                                                                                           with ViT-B and ViT-S.
 Sup. [69]    99.0    89.5      70.7   76.6     98.2 92.1 79.9                         74                                           Models are trained for
 DINO         99.0    90.5      72.0   78.2     98.5 93.0 81.5                                                             16x16
                                                                                       72                                           300 epochs.
 ViT-B/16                                                                                          102                     103
 Sup. [69]    99.0    90.8      73.2   77.7     98.4 92.1 81.8                                    throughput (im/s)
 DINO         99.1    91.7      72.6   78.6     98.8 93.0 82.8

                                                                        with different patch sizes, 16 × 16, 8 × 8 and 5 × 5. We
   In Table 7, we report different model variants as we add             also compare to ViT-B with 16 × 16 and 8 × 8 patches. All
or remove components. First, we observe that in the absence             the models are trained for 300 epochs. We observe that the
of momentum, our framework does not work (row 2) and                    performance greatly improves as we decrease the size of the
more advanced operations, SK for example, are required to               patch. It is interesting to see that performance can be greatly
avoid collapse (row 9). However, with momentum, using                   improved without adding additional parameters. However,
SK has little impact (row 3). In addtition, comparing rows 3            the performance gain from using smaller patches comes at
and 9 highlights the importance of the momentum encoder                 the expense of throughput: when using 5×5 patches, the
for performance. Second, in rows 4 and 5, we observe that               throughput falls to 44 im/s, vs 180 im/s for 8×8 patches.
multi-crop training and the cross-entropy loss in DINO are
important components to obtain good features. We also ob-                5.2. Impact of the choice of Teacher Network
serve that adding a predictor to the student network has little              In this ablation, we experiment with different teacher
impact (row 6) while it is critical in BYOL to prevent col-              network to understand its role in DINO. We compare models
lapse [16, 30]. For completeness, we propose in Appendix B               trained for 300 epochs using the k-NN protocol.
an extended version of this ablation study.

                                                                         Building different teachers from the student. In
Importance of the patch size. In Fig. 5, we compare the                  Fig. 6(right), we compare different strategies to build the
k-NN classification performance of ViT-S models trained                  teacher from previous instances of the student besides the
        72                             Teacher           Top-1
                                                                                           sharpening                          centering            both
val acc@1


                                                                                     8
        68




                                                                    Target Entropy
                                       Student copy        0.1




                                                                                                               KL divergence
                       Student         Previous iter       0.1                       6                                         2
                       Teacher         Previous epoch     66.6                       4
        64                             Momentum           72.8                       2
             0   100 200         300                                                 0                                         0
                   epochs
                                                                                      0     epochs        100                   0          epochs      100
Figure 6: Top-1 accuracy on ImageNet validation with k-NN classi-
fier. (left) Comparison between the performance of the momentum      Figure 7: Collapse study. (left): evolution of the teacher’s target
teacher and the student during training. (right) Comparison be-      entropy along training epochs; (right): evolution of KL divergence
tween different types of teacher network. The momentum encoder       between teacher and student outputs.
leads to the best performance but is not the only viable option.
                                                                     Table 8: Time and memory requirements. We show total running
                                                                     time and peak memory per GPU (“mem.”) when running ViT-S/16
momentum teacher. First we consider using the student net-           DINO models on two 8-GPU machines. We report top-1 ImageNet
work from a previous epoch as a teacher. This strategy has           val acc with linear evaluation for several variants of multi-crop,
                                                                     each having a different level of compute requirement.
been used in a memory bank [73] or as a form of clustering
hard-distillation [8, 2, 14]. Second, we consider using the
student network from the previous iteration, as well as a                                               100 epochs                    300 epochs
copy of the student for the teacher. In our setting, using a           multi-crop                       top-1           time         top-1     time mem.
teacher based on a recent version of the student does not
                                                                       2×2242                           67.8        15.3h            72.5     45.9h 9.3G
converge. This setting requires more normalizations to work.
                                                                       2×2242 + 2×962                   71.5        17.0h            74.5     51.0h 10.5G
Interestingly, we observe that using a teacher from the previ-
                                                                       2×2242 + 6×962                   73.8        20.3h            75.9     60.9h 12.9G
ous epoch does not collapse, providing performance in the
                                                                       2×2242 + 10×962                  74.6        24.2h            76.1     72.6h 15.4G
k-NN evaluation competitive with existing frameworks such
as MoCo-v2 or BYOL. While using a momentum encoder
clearly provides superior performance to this naive teacher,        collapse: regardless of the input, the model output is uniform
this finding suggests that there is a space to investigate alter-   along all the dimensions or dominated by one dimension.
natives for the teacher.                                            The centering avoids the collapse induced by a dominant
                                                                    dimension, but encourages an uniform output. Sharpening
Analyzing the training dynamic. To further understand               induces the opposite effect. We show this complementarity
the reasons why a momentum teacher works well in our                by decomposing the cross-entropy H into an entropy h and
framework, we study its dynamic during the training of a            the Kullback-Leibler divergence (“KL”) DKL :
ViT in the left panel of Fig. 6. A key observation is that
this teacher constantly outperforms the student during the                                H(Pt , Ps ) = h(Pt ) + DKL (Pt |Ps ).                            (5)
training, and we observe the same behavior when training            A KL equal to zero indicates a constant output, and hence
with a ResNet-50 (Appendix D). This behavior has not been           a collapse. In Fig. 7, we plot the entropy and KL during
observed by other frameworks also using momentum [33,               training with and without centering and sharpening. If one
30], nor when the teacher is built from the previous epoch.         operation is missing, the KL converges to zero, indicating
We propose to interpret the momentum teacher in DINO                a collapse. However, the entropy h converges to different
as a form of Polyak-Ruppert averaging [51, 59] with an              values: 0 with no centering and − log(1/K) with no sharp-
exponentially decay. Polyak-Ruppert averaging is often used         ening, indicating that both operations induce different form
to simulate model ensembling to improve the performance             of collapse. Applying both operations balances these effects
of a network at the end of the training [38]. Our method can        (see study of the sharpening parameter τt in Appendix D).
be interpreted as applying Polyak-Ruppert averaging during
the training to constantly build a model ensembling that has         5.4. Compute requirements
superior performances. This model ensembling then guides                In Tab. 8, we detail the time and GPU memory require-
the training of the student network [65].                            ments when running ViT-S/16 DINO models on two 8-GPU
                                                                     machines. We report results with several variants of multi-
5.3. Avoiding collapse
                                                                     crop training, each having a different level of compute re-
   We study the complementarity role of centering and tar-           quirement. We observe in Tab. 8 that using multi-crop im-
get sharpening to avoid collapse. There are two forms of             proves the accuracy / running-time tradeoff for DINO runs.
For example, the performance is 72.5% after 46 hours of           ViT. In the future, we plan to explore if pretraining a large
training without multi-crop (i.e. 2×2242 ) while DINO in          ViT model with DINO on random uncurated images could
2×2242 +10×962 crop setting reaches 74.6% in 24 hours only.       push the limits of visual features [28].
This is an improvement of +2% while requiring 2× less time,
though the memory usage is higher (15.4G versus 9.3G). We
                                                                  Acknowledgement. We thank Mahmoud Assran, Matthijs
observe that the performance boost brought with multi-crop
                                                                  Douze, Allan Jabri, Jure Zbontar, Alaaeldin El-Nouby, Y-
cannot be caught up by more training in the 2×2242 setting,
                                                                  Lan Boureau, Kaiming He, Thomas Lucas as well as the
which shows the value of the “local-to-global” augmentation.
                                                                  Thoth and FAIR teams for their help, support and discussions
Finally, the gain from adding more views diminishes (+.2%
                                                                  around this project. Julien Mairal was funded by the ERC
form 6× to 10× 962 crops) for longer trainings.
                                                                  grant number 714381 (SOLARIS project) and by ANR 3IA
   Overall, training DINO with Vision Transformers
                                                                  MIAI@Grenoble Alpes (ANR-19-P3IA-0003).
achieves 76.1 top-1 accuracy using two 8-GPU servers for 3
days. This result outperforms state-of-the-art self-supervised
systems based on convolutional networks of comparable             References
sizes with a significant reduction of computational require-       [1] Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Or-
ments [30, 10]. Our code is available to train self-supervised         mandi, George E Dahl, and Geoffrey E Hinton. Large scale
ViT on a limited number of GPUs.                                       distributed neural network training through online distillation.
                                                                       arXiv preprint arXiv:1804.03235, 2018. 3
5.5. Training with small batches                                   [2] Yuki Markus Asano, Christian Rupprecht, and Andrea
                                                                       Vedaldi. Self-labelling via simultaneous clustering and repre-
                                    Table 9: Effect of batch           sentation learning. In ICLR, 2020. 2, 9
bs      128   256    512   1024     sizes. Top-1 with k-NN         [3] Mahmoud Assran, Nicolas Ballas, Lluis Castrejon, and
top-1   57.9 59.1 59.6     59.9     for models trained for 100         Michael Rabbat. Recovering petaflops in contrastive semi-
                                    epochs without multi-crop.         supervised learning of visual representations. preprint
                                                                       arXiv:2006.10803, 2020. 14
    In Tab. 9, we study the impact of the batch size on the        [4] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
features obtained with DINO. We also study the impact                  Neural machine translation by jointly learning to align and
of the smooth parameter m used in the centering update                 translate. preprint arXiv:1409.0473, 2014. 5
rule of Eq. 4 in Appendix D. We scale the learning rate lin-       [5] Maxim Berman, Hervé Jégou, Vedaldi Andrea, Iasonas
early with the batch size [29]: lr = 0.0005 ∗ batchsize/256.           Kokkinos, and Matthijs Douze. MultiGrain: a unified im-
                                                                       age embedding for classes and instances. arXiv preprint
Tab. 9 confirms that we can train models to high perfor-
                                                                       arXiv:1902.05509, 2019. 6
mance with small batches. Results with the smaller batch
                                                                   [6] Piotr Bojanowski and Armand Joulin. Unsupervised learning
sizes (bs = 128) are slightly below our default training setup
                                                                       by predicting noise. In ICML, 2017. 2
of bs = 1024, and would certainly require to re-tune hyper-
                                                                   [7] Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-
parameters like the momentum rates for example. Note that
                                                                       Mizil. Model compression. In SIGKDD, 2006. 3
the experiment with batch size of 128 runs on only 1 GPU.
                                                                   [8] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and
We have explored training a model with a batch size of 8,
                                                                       Matthijs Douze. Deep clustering for unsupervised learning of
reaching 35.2% after 50 epochs, showing the potential for              visual features. In ECCV, 2018. 2, 4, 9, 16
training large models that barely fit an image per GPU.
                                                                   [9] Mathilde Caron, Piotr Bojanowski, Julien Mairal, and Ar-
                                                                       mand Joulin. Unsupervised pre-training of image features on
6. Conclusion                                                          non-curated data. In ICCV, 2019. 2, 16
   In this work, we have shown the potential of self-             [10] Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal,
                                                                       Piotr Bojanowski, and Armand Joulin. Unsupervised learn-
supervised pretraining a standard ViT model, achieving per-
                                                                       ing of visual features by contrasting cluster assignments. In
formance that are comparable with the best convnets specifi-
                                                                       NeurIPS, 2020. 1, 2, 3, 4, 5, 7, 8, 10, 14, 15, 16, 17, 18
cally designed for this setting. We have also seen emerged
                                                                  [11] Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson,
two properties that can be leveraged in future applications:
                                                                       Wolfgang Macherey, George Foster, Llion Jones, Niki Parmar,
the quality of the features in k-NN classification has a po-           Mike Schuster, Zhifeng Chen, et al. The best of both worlds:
tential for image retrieval where ViT are already showing              Combining recent advances in neural machine translation.
promising results [22]. The presence of information about              preprint arXiv:1804.09849, 2018. 5
the scene layout in the features can also benefit weakly super-   [12] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geof-
vised image segmentation. However, the main result of this             frey Hinton. A simple framework for contrastive learning of
paper is that we have evidences that self-supervised learning          visual representations. preprint arXiv:2002.05709, 2020. 2,
could be the key to developing a BERT-like model based on              3, 5, 16, 17
[13] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad                [29] Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noord-
     Norouzi, and Geoffrey Hinton. Big self-supervised models                huis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch,
     are strong semi-supervised learners. In NeurIPS, 2020. 3, 5,            Yangqing Jia, and Kaiming He. Accurate, large minibatch
     6, 14                                                                   sgd: Training imagenet in 1 hour. preprint arXiv:1706.02677,
[14] Weijie Chen, Shiliang Pu, Di Xie, Shicai Yang, Yilu Guo,                2017. 5, 10
     and Luojun Lin. Unsupervised image classification for deep         [30] Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin
     representation learning. arXiv preprint arXiv:2006.11480,               Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Do-
     2020. 9, 15                                                             ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham-
[15] Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.                  mad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi
     Improved baselines with momentum contrastive learning.                  Munos, and Michal Valko. Bootstrap your own latent: A new
     preprint arXiv:2003.04297, 2020. 5, 8, 14, 15, 18                       approach to self-supervised learning. In NeurIPS, 2020. 2, 3,
[16] Xinlei Chen and Kaiming He. Exploring simple siamese                    4, 5, 8, 9, 10, 14, 15, 16, 18
     representation learning. preprint arXiv:2011.10566, 2020. 2,       [31] Shir Gur, Ameen Ali, and Lior Wolf. Visualization of su-
     3, 4, 8, 14, 16, 18                                                     pervised and self-supervised neural networks via attribution
[17] Marco Cuturi. Sinkhorn distances: Lightspeed computation                guided factorization. preprint arXiv:2012.02166, 2020. 7
     of optimal transport. In NeurIPS, 2013. 15                         [32] Michael Gutmann and Aapo Hyvärinen. Noise-contrastive
[18] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina                  estimation: A new estimation principle for unnormalized
     Toutanova. Bert: Pre-training of deep bidirectional transform-          statistical models. In International Conference on Artificial
     ers for language understanding. preprint arXiv:1810.04805,              Intelligence and Statistics, 2010. 2
     2018. 1, 4, 5, 19                                                  [33] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross
[19] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,                  Girshick. Momentum contrast for unsupervised visual rep-
     Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,                     resentation learning. In CVPR, 2020. 1, 2, 3, 4, 5, 7, 9,
     Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-                16
     vain Gelly, et al. An image is worth 16x16 words: Transform-       [34] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
     ers for image recognition at scale. preprint arXiv:2010.11929,          Deep residual learning for image recognition. In CVPR, 2016.
     2020. 1, 4, 5, 13                                                       4, 5
[20] Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springen-         [35] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the
     berg, Martin Riedmiller, and Thomas Brox. Discriminative                knowledge in a neural network. preprint arXiv:1503.02531,
     unsupervised feature learning with exemplar convolutional               2015. 2, 3
     neural networks. TPAMI, 2016. 2
                                                                        [36] Jiabo Huang, Qi Dong, Shaogang Gong, and Xiatian Zhu.
[21] Matthijs Douze, Hervé Jégou, Harsimrat Sandhawalia, Lau-              Unsupervised deep learning by neighbourhood discovery. In
     rent Amsaleg, and Cordelia Schmid. Evaluation of gist de-               ICML, 2019. 2
     scriptors for web-scale image search. In CIVR, 2009. 6
                                                                        [37] Allan Jabri, Andrew Owens, and Alexei A Efros. Space-time
[22] Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, and
                                                                             correspondence as a contrastive random walk. 2020. 7
     Hervé Jégou. Training vision transformers for image retrieval.
     preprint arXiv:2102.05644, 2021. 10                                [38] Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and
                                                                             Yoshua Bengio. On using very large target vocabulary for
[23] Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto,
                                                                             neural machine translation. preprint arXiv:1412.2007, 2014.
     and Nicu Sebe. Whitening for self-supervised representation
                                                                             4, 9
     learning. preprint arXiv:2007.06346, 2020. 2
                                                                        [39] Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart,
[24] Mark Everingham, Luc Van Gool, Christopher KI Williams,
                                                                             and Alexander M Rush. Opennmt: Open-source toolkit for
     John Winn, and Andrew Zisserman. The pascal visual object
                                                                             neural machine translation. preprint arXiv:1701.02810, 2017.
     classes (voc) challenge. IJCV, 2010. 13
                                                                             5
[25] Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang,
     Yezhou Yang, and Zicheng Liu. Seed: Self-supervised distil-        [40] Zihang Lai, Erika Lu, and Weidi Xie. Mast: A memory-
     lation for visual representation. 2021. 3                               augmented self-supervised tracker. In CVPR, 2020. 7
[26] Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick            [41] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient
     Pérez, and Matthieu Cord. Learning representations by pre-             semi-supervised learning method for deep neural networks.
     dicting bags of visual words. In CVPR, 2020. 2                          In Workshop on challenges in representation learning, ICML,
[27] Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Komodakis,             2013. 3
     Matthieu Cord, and Patrick Pérez. Online bag-of-visual-           [42] Junnan Li, Pan Zhou, Caiming Xiong, and Steven C.H. Hoi.
     words generation for unsupervised representation learning.              Prototypical contrastive learning of unsupervised representa-
     arXiv preprint arXiv:2012.11552, 2020. 2, 5                             tions. ICLR, 2021. 2
[28] Priya Goyal, Mathilde Caron, Benjamin Lefaudeux, Min               [43] Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient
     Xu, Pengchao Wang, Vivek Pai, Mannat Singh, Vitaliy                     descent with warm restarts. preprint arXiv:1608.03983, 2016.
     Liptchinsky, Ishan Misra, Armand Joulin, et al. Self-                   5
     supervised pretraining of visual features in the wild. preprint    [44] Ilya Loshchilov and Frank Hutter. Fixing weight decay regu-
     arXiv:2103.01988, 2021. 10                                              larization in adam. 2018. 5
[45] Julien Mairal. Cyanure: An open-source toolbox for empirical     [62] Mert Bulent Sariyildiz, Yannis Kalantidis, Diane Larlus, and
     risk minimization for python, c++, and soon more. preprint            Karteek Alahari. Concept generalization in visual representa-
     arXiv:1912.08165, 2019. 13, 14                                        tion learning. arXiv preprint arXiv:2012.05649, 2020. 7
[46] Maria-Elena Nilsback and Andrew Zisserman. Automated             [63] Zhiqiang Shen, Zechun Liu, Jie Qin, Lei Huang, Kwang-
     flower classification over a large number of classes. In 2008         Ting Cheng, and Marios Savvides. S2-bnn: Bridging
     Sixth Indian Conference on Computer Vision, Graphics &                the gap between self-supervised real and 1-bit neural net-
     Image Processing, 2008. 13                                            works via guided distribution calibration. arXiv preprint
[47] Mehdi Noroozi, Ananth Vinjimoor, Paolo Favaro, and Hamed              arXiv:2102.08946, 2021. 3
     Pirsiavash. Boosting self-supervised learning via knowledge      [64] Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang,
     transfer. In CVPR, 2018. 3                                            Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Han Zhang,
[48] Seoung Wug Oh, Joon-Young Lee, Ning Xu, and Seon Joo                  and Colin Raffel. Fixmatch: Simplifying semi-supervised
     Kim. Video object segmentation using space-time memory                learning with consistency and confidence. In NeurIPS, 2020.
     networks. In ICCV, 2019. 7                                            14
[49] Hieu Pham, Qizhe Xie, Zihang Dai, and Quoc V Le. Meta            [65] Antti Tarvainen and Harri Valpola. Mean teachers are
     pseudo labels. preprint arXiv:2003.10580, 2020. 14                    better role models: Weight-averaged consistency targets
[50] James Philbin, Ondrej Chum, Michael Isard, Josef Sivic,               improve semi-supervised deep learning results. preprint
     and Andrew Zisserman. Lost in quantization: Improving                 arXiv:1703.01780, 2017. 3, 4, 9, 17
     particular object retrieval in large scale image databases. In   [66] Bart Thomee, David A Shamma, Gerald Friedland, Benjamin
     CVPR, 2008. 6                                                         Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia
[51] Boris T Polyak and Anatoli B Juditsky. Acceleration of                Li. Yfcc100m: The new data in multimedia research. arXiv
     stochastic approximation by averaging. SIAM journal on                preprint arXiv:1503.01817, 2015. 6
     control and optimization, 30(4):838–855, 1992. 4, 9, 17          [67] Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan,
[52] Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Ar-          Cordelia Schmid, and Phillip Isola. What makes for good
     beláez, Alex Sorkine-Hornung, and Luc Van Gool. The                  views for contrastive learning. NeurIPS, 2020. 5
     2017 davis challenge on video object segmentation. preprint      [68] Giorgos Tolias, Ronan Sicre, and Hervé Jégou. Particular
     arXiv:1704.00675, 2017. 7                                             object retrieval with integral max-pooling of cnn activations.
[53] Filip Radenović, Ahmet Iscen, Giorgos Tolias, Yannis                 arXiv preprint arXiv:1511.05879, 2015. 6
     Avrithis, and Ondřej Chum. Revisiting oxford and paris:
                                                                      [69] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco
     Large-scale image retrieval benchmarking. 2018. 6
                                                                           Massa, Alexandre Sablayrolles, and Hervé Jégou. Training
[54] Filip Radenović, Giorgos Tolias, and Ondřej Chum. Fine-             data-efficient image transformers & distillation through atten-
     tuning cnn image retrieval with no human annotation. IEEE             tion. preprint arXiv:2012.12877, 2020. 1, 4, 5, 6, 7, 8, 13,
     transactions on pattern analysis and machine intelligence,            17
     2018. 6
                                                                      [70] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-
[55] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario              reit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia
     Amodei, and Ilya Sutskever. Language models are unsuper-              Polosukhin. Attention is all you need. In NeurIPS, 2017. 1, 4
     vised multitask learners. 1
                                                                      [71] Xiaolong Wang, Allan Jabri, and Alexei A Efros. Learning
[56] Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaim-
                                                                           correspondence from the cycle-consistency of time. In CVPR,
     ing He, and Piotr Dollár. Designing network design spaces.
                                                                           2019. 7
     In CVPR, 2020. 13
                                                                      [72] Tobias Weyand, Andre Araujo, Bingyi Cao, and Jack Sim.
[57] Jerome Revaud, Jon Almazán, Rafael S Rezende, and Cesar
                                                                           Google landmarks dataset v2-a large-scale benchmark for
     Roberto de Souza. Learning with average precision: Training
                                                                           instance-level recognition and retrieval. 2020. 6
     image retrieval with a listwise loss. In ICCV, 2019. 6
[58] Pierre H Richemond, Jean-Bastien Grill, Florent Altché,         [73] Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin.
     Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith,           Unsupervised feature learning via non-parametric instance
     Soham De, Razvan Pascanu, Bilal Piot, et al. Byol works even          discrimination. In CVPR, 2018. 2, 4, 5, 9, 18
     without batch statistics. preprint arXiv:2010.10241, 2020. 2,    [74] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised
     4                                                                     deep embedding for clustering analysis. In ICML, 2016. 2
[59] David Ruppert. Efficient estimations from a slowly conver-       [75] Qizhe Xie, Zihang Dai Dai, Eduard Hovy, Minh-Thang Lu-
     gent robbins-monro process. Technical report, 1988. 4, 9              ong, and Quoc V. Le. Unsupervised data augmentation for
[60] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-             consistency training. preprint arXiv:1904.12848, 2020. 14
     jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,          [76] Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V
     Aditya Khosla, Michael Bernstein, Alexander C Berg, and Li            Le. Self-training with noisy student improves imagenet clas-
     Fei-Fei. Imagenet large scale visual recognition challenge.           sification. In CVPR, 2020. 3
     IJCV, 2015. 1, 5, 13                                             [77] Haohang Xu, Xiaopeng Zhang, Hao Li, Lingxi Xie, Hongkai
[61] Tim Salimans and Diederik P Kingma. Weight normalization:             Xiong, and Qi Tian. Seed the views: Hierarchical seman-
     A simple reparameterization to accelerate training of deep            tic alignment for contrastive representation learning. arXiv
     neural networks. NeurIPS, 2016. 4, 16                                 preprint arXiv:2012.02733, 2021. 16
[78] Qiantong Xu, Tatiana Likhomanenko, Jacob Kahn, Awni             Table 10: k-NN and linear evaluation for ViT-S/16 and ResNet-
     Hannun, Gabriel Synnaeve, and Ronan Collobert. Iter-            50 pre-trained with DINO. We use ImageNet-1k [60] (“Inet”),
     ative pseudo-labeling for speech recognition. preprint          Places205 [84], PASCAL VOC [24] and Oxford-102 flowers
     arXiv:2005.09267, 2020. 3                                       (“FLOWERS”) [46]. ViT trained with DINO provides features
[79] I Zeki Yalniz, Hervé Jégou, Kan Chen, Manohar Paluri, and     that are particularly k-NN friendly.
     Dhruv Mahajan. Billion-scale semi-supervised learning for
     image classification. preprint arXiv:1905.00546, 2019. 3                                 Logistic                        k-NN
[80] Jianwei Yang, Devi Parikh, and Dhruv Batra. Joint unsuper-                      RN50       ViT-S    ∆             RN50    ViT-S      ∆
     vised learning of deep representations and image clusters. In
     CVPR, 2016. 2                                                    Inet 100%       72.1      75.7      3.6          67.5      74.5     7.0
                                                                      Inet 10%        67.8      72.2      4.4          59.3      69.1     9.8
[81] Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and Stéphane
                                                                      Inet 1%         55.1      64.5      9.4          47.2      61.3    14.1
     Deny. Barlow twins: Self-supervised learning via redundancy
                                                                      Pl. 10%         53.4      52.1     -1.3          46.9      48.6     1.7
     reduction. arXiv preprint arXiv:2103.03230, 2021. 2, 5
                                                                      Pl. 1%          46.5      46.3     -0.2          39.2      41.3     2.1
[82] Richard Zhang, Phillip Isola, and Alexei A Efros. Colorful
                                                                      VOC07           88.9      89.2      0.3          84.9      88.0     3.1
     image colorization. In ECCV, 2016. 5
                                                                      FLOWERS         95.6      96.4      0.8          87.9      89.1     1.2
[83] Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun. Exploring
     self-attention for image recognition. In CVPR, 2020. 1           Average ∆                          2.4                              5.6
[84] Bolei Zhou, Agata Lapedriza, Jianxiong Xiao, Antonio Tor-
     ralba, and Aude Oliva. Learning deep features for scene
     recognition using places database. In NeurIPS, 2014. 13         Table 11: ImageNet classification with different pretraining.
[85] Chengxu Zhuang, Alex Lin Zhai, and Daniel Yamins. Local         Top-1 accuracy on ImageNet for supervised ViT-B/16 models using
     aggregation for unsupervised learning of visual embeddings.     different pretrainings or using an additional pretrained convnet to
     In ICCV, 2019. 2                                                guide the training. The methods use different image resolution
                                                                     (“res.”) and training procedure (“tr. proc.”), i.e., data augmentation
Appendix                                                             and optimization. “MPP” is Masked Patch Prediction.

A. Additional Results                                                          Pretraining
k-NN classification. In Tab. 10, we evaluate the frozen               method                 data               res.    tr. proc.       Top-1
representations given by ResNet-50 or ViT-small pre-trained
                                                                      Pretrain on additional data
with DINO with two evaluation protocols: linear or k-NN.
                                                                      MMP           JFT-300M                   384        [19]          79.9
For both evaluations, we extract representations from a pre-
                                                                      Supervised JFT-300M                      384        [19]          84.2
trained network without using any data augmentation. Then,
we perform classification either with weighted k-NN or with           Train with additional model
a linear regression learned with cyanure library [45]. In             Rand. init.        -                     224        [69]          83.4
Tab. 10 we see that ViT-S accuracies are better than accu-            No additional data nor model
racies obtained with RN50 both with a linear or a k-NN                Rand. init.        -                     224        [19]          77.9
classifier. However, the performance gap when using the               Rand. init.        -                     224        [69]          81.8
k-NN evaluation is much more significant than when consid-            Supervised      ImNet                    224        [69]          81.9
ering linear evaluation. For example on ImageNet 1%, ViT-S            DINO            ImNet                    224        [69]          82.8
outperforms ResNet-50 by a large margin of +14.1% with
k-NN evaluation. This suggests that transformers architec-
tures trained with DINO might offer more model flexibility
that benefits the k-NN evaluation. K-NN classifiers have             pretrained with and without supervision on the large curated
the great advantage of being fast and light to deploy, without       dataset composed of 300M images. The second set of mod-
requiring any domain adaptation. Overall, ViT trained with           els are trained with hard knowledge distillation from a pre-
DINO provides features that combine particularly well with           trained supervised RegNetY [56]. The last set of models do
k-NN classifiers.                                                    not use any additional data nor models, and are initialized ei-
                                                                     ther randomly or after a pretraining with DINO on ImageNet.
Self-supervised ImageNet pretraining of ViT. In this ex-             Compare to random initialization, pretraining with DINO
periment, we study the impact of pretraining a supervised            leads to a performance gain of +1%. This is not caused by a
ViT model with our method. In Tab. 11, we compare the                longer training since pretraining with supervision instead of
performance of supervised ViT models that are initialized            DINO does not improve performance. Using self-supervised
with different pretraining or guided during training with an         pretraining reduces the gap with models pretrained on extra
additional pretrained convnet. The first set of models are           data or distilled from a convnet.
Table 12: Low-shot learning on ImageNet with frozen ViT fea-         Table 13: Methodology comparison for DEIT-small and
tures. We train a logistic regression on frozen features (FROZEN).   ResNet-50. We report ImageNet linear and k-NN evaluations
Note that this FROZEN evaluation is performed without any fine-      validation accuracy after 300 epochs pre-training. All numbers are
tuning nor data augmentation. We report top-1 accuracy. For          run by us and match or outperform published results.
reference, we show previously published results that uses finetun-
ing and semi-supervised learning.                                                           ResNet-50              ViT-small

                                                      Top 1             Method            Linear    k-NN         Linear     k-NN
Method                  Arch              Param.     1%    10%          MoCo-v2            71.1      62.9         71.6       62.0
Self-supervised pretraining with finetuning                             BYOL               72.7      65.4         71.4       66.6
UDA [75]                 RN50                23       –     68.1        SwAV               74.1      65.4         71.8       64.7
SimCLRv2 [13]            RN50                23      57.9   68.4
                                                                        DINO               74.5      65.6         76.1       72.8
BYOL [30]                RN50                23      53.2   68.8
SwAV [10]                RN50                23      53.9   70.2
SimCLRv2 [16]            RN50w4             375      63.0   74.4
BYOL [30]                RN200w2            250      71.2   77.7     Relation to MoCo-v2 and BYOL. In Tab. 14, we present
                                                                     the impact of ablating components that differ between DINO,
Semi-supervised methods
SimCLRv2+KD [13] RN50                       23       60.0   70.5
                                                                     MoCo-v2 and BYOL: the choice of loss, the predictor in the
SwAV+CT [3]           RN50                  23        –     70.8     student head, the centering operation, the batch normaliza-
FixMatch [64]         RN50                  23        –     71.5     tion in the projection heads, and finally, the multi-crop aug-
MPL [49]              RN50                  23        –     73.9     mentation. The loss in DINO is a cross-entropy on sharpened
SimCLRv2+KD [13] RN152w3+SK                 794      76.6   80.9     softmax outputs (CE) while MoCo-v2 uses the InfoNCE con-
Frozen self-supervised features
                                                                     trastive loss (INCE) and BYOL a mean squared error on
DINO - FROZEN            ViT-S/16            21      64.5   72.2     l2-normalized outputs (MSE). No sharpening is applied with
                                                                     the MSE criterion. Though, DINO surprisingly still works
                                                                     when changing the loss function to MSE, but this signifi-
                                                                     cantly alters the performance (see rows (1, 2) and (4, 9)).
Low-shot learning on ImageNet. We evaluate the fea-                  We also observe that adding a predictor has little impact (1,
tures obtained with DINO applied on ViT-S on low-shot                3). However, in the case of BYOL, the predictor is critical
learning. In Tab. 12, we report the validation accuracy of           to prevent collapse (7, 8) which is consistent with previous
a logistic regression trained on frozen features (FROZEN)            studies [16, 30]. Interestingly, we observe that the teacher
with 1% and 10% labels. The logistic regression is trained           output centering avoids collapse without predictor nor batch
with the cyanure library [45]. When comparing mod-                   normalizations in BYOL (7, 9), though with a significant
els with a similar number of parameters and image/sec, we            performance drop which can likely be explained by the fact
observe that our features are on par with state-of-the-art           that our centering operator is designed to work in combina-
semi-supervised models. Interestingly, this performance              tion with sharpening. Finally, we observe that multi-crop
is obtained by training a multi-class logistic regression on         works particularly well with DINO and MoCo-v2, removing
frozen features, without data augmentation nor finetuning.           it hurts performance by 2 − 4% (1 versus 4 and, 5 versus 6).
                                                                     Adding multi-crop to BYOL does not work out-of-the-box
                                                                     (7, 10) as detailed in Appendix E and further adaptation may
B. Methodology Comparison                                            be required.
    We compare the performance of different self-supervised
frameworks, MoCo-v2 [15], SwAV [10] and BYOL [30]                    Relation to SwAV. In Tab. 15, we evaluate the differences
when using convnet or ViT. In Tab. 13, we see that when              between DINO and SwAV: the presence of the momentum
trained with ResNet-50 (convnet), DINO performs on par               encoder and the operation on top of the teacher output. In
with SwAV and BYOL. However, DINO unravels its poten-                absence of the momentum, a copy of the student with a stop-
tial with ViT, outperforming MoCo-v2, SwAV and BYOL                  gradient is used. We consider three operations on the teacher
by large margins (+4.3% with linear and +6.2% with k-NN              output: Centering, Sinkhorn-Knopp or a Softmax
evaluations). In the rest of this section, we perform ablations      along the batch axis. The Softmax is similar to a single
to better understand the performance of DINO applied to ViT.         Sinkhorn-Knopp iteration as detailed in the next paragraph.
In particular, we provide a detailed comparison with meth-           First, these ablations show that using a momentum encoder
ods that either use a momentum encoder, namely MoCo-v2               significantly improves the performance for ViT (3 versus 6,
and BYOL, and methods that use multi-crop, namely SwAV.              and 2 versus 5). Second, the momentum encoder also avoids
                                                                     collapse when using only centering (row 1). In the absence
Figure 8: Self-attention for a set of reference points. We visualize the self-attention module from the last block of a ViT-S/8 trained with
DINO. The network is able to separate objects, though it has been trained with no supervision at all.


Table 14: Relation to MoCo-v2 and BYOL. We ablate the com-               removing the need for normalization beyond centering.
ponents that differ between DINO, MoCo-v2 and BYOL: the loss
function (cross-entropy, CE, versus InfoNCE, INCE, versus mean-
square error, MSE), the multi-crop training, the centering operator,     Details on the Softmax(batch) variant. The itera-
the batch normalization in the projection heads and the student          tive Sinkhorn-Knopp algorithm [17] used in SwAV [10] is
predictor. Models are run for 300 epochs with ViT-S/16. We report        implemented simply with the following PyTorch style code.
top-1 accuracy on ImageNet linear evaluation.
                                                                         # x is n-by-K
                                                                         # tau is Sinkhorn regularization param
     Method      Loss       multi-crop Center. BN Pred. Top-1            x = exp(x / tau)
                                                                         for _ in range(num_iters): # 1 iter of Sinkhorn
1    DINO         CE           X         X                    76.1         # total weight per dimension (or cluster)
2    –           MSE           X         X                    62.4         c = sum(x, dim=0, keepdim=True)
3    –            CE           X         X             X      75.6         x /= c
4    –            CE                     X                    72.5
                                                                           # total weight per sample
5    MoCov2 INCE                                X             71.4         n = sum(x, dim=1, keepdim=True)
6           INCE               X                X             73.4         # x sums to 1 for each sample (assignment)
                                                                           x /= n
7    BYOL        MSE                            X      X      71.4
8    –           MSE                            X              0.1       When performing a single Sinkhorn iteration
9    –           MSE                     X                    52.6       (num iters=1) the implementation can be highly
10   –           MSE           X                X      X      64.8       simplified into only two lines of code, which is our
                                                                         softmax(batch) variant:
Table 15: Relation to SwAV. We vary the operation on the teacher         x = softmax(x / tau, dim=0)
output between centering, a softmax applied over the batch di-           x /= sum(x, dim=1, keepdim=True)
mension and the Sinkhorn-Knopp algorithm. We also ablate the
Momentum encoder by replacing it with a hard copy of the student         We have seen in Tab. 15 that this highly simplified variant
with a stop-gradient as in SwAV. Models are run for 300 epochs           of SwAV works competitively with SwAV. Intuitively, the
with ViT-S/16. We report top-1 accuracy on ImageNet linear evalu-        softmax operation on the batch axis allows to select for
ation.
                                                                         each dimension (or “cluster”) its best matches in the batch.

     Method      Momentum               Operation            Top-1
                                                                         Validating our implementation. We observe in Tab. 13
1    DINO               X             Centering               76.1       that our reproduction of BYOL, MoCo-v2, SwAV matches
2    –                  X          Softmax(batch)             75.8       or outperforms the corresponding published numbers with
3    –                  X          Sinkhorn-Knopp             76.0       ResNet-50. Indeed, we obtain 72.7% for BYOL while [30]
4    –                                Centering                0.1       report 72.5% in this 300-epochs setting. We obtain 71.1%
5    –                             Softmax(batch)             72.2       for MoCo after 300 epochs of training while [15] report
6    SwAV                          Sinkhorn-Knopp             71.8       71.1% after 800 epochs of training. Our improvement com-
                                                                         pared to the implementation of [15] can be explained by
                                                                         the use of a larger projection head (3-layer, use of batch-
of momentum, centering the outputs does not work (4) and                 normalizations and projection dimension of 256).
more advanced operations are required (5, 6). Overall, these
ablations highlight the importance of the momentum en-                   Relation to other works. DINO is also related to
coder, not only for performance but also to stabilize training,          UIC [14] that use outputs from the previous epoch as hard
pseudo-labels for “unsupervised classification”. However,                            w/ l2-bottleneck                                             w/o l2-bottleneck
we use centering to prevent collapse while UIC resorts to
balance sampling techniques as in [8]. Our work can be                                     g(x)                                                          g(x)
interpreted as a soft UIC variant with momentum teacher.
                                                                                                  BxK                                                           BxK
   The concurrent work CsMI [77] also exhibits strong per-




                                                                 projection head h




                                                                                                                              projection head h
formance with simple k-NN classifiers on ImageNet, even                                linear layer
with convnets. As DINO, CsMI combines a momentum net-                                             B x 256

work and multi-crop training, which we have seen are both                            l2 normalization
                                                                                                  B x 256
crucial for good k-NN performance in our experiments with
                                                                                       n-layer MLP                                                  n-layer MLP
ViTs. We believe studying this work would help us identify-
                                                                                                  B x 384                                                       B x 384
ing more precisely the components important for good k-NN
performance and leave this investigation for future work.                                   f                                                             f


C. Projection Head                                                                          x     B x 3 x 224 x 224                                       x     B x 3 x 224 x 224


   Similarly to other self-supervised frameworks, using a        Figure 9: Projection head design w/ or w/o l2-norm bottleneck.
projection head [12] improves greatly the accuracy of our
method. The projection head starts with a n-layer multi-
layer perceptron (MLP). The hidden layers are 2048d and          linear layers is n + 1 (n from the MLP and 1 from the
are with gaussian error linear units (GELU) activations. The     weight normalized layer) while without bottleneck the to-
last layer of the MLP is without GELU. Then we apply a           tal number of linear layers is n in the head. In this table,
`2 normalization and a weight normalized fully connected         we report ImageNet top-1 k-NN evaluation accuracy after
layer [16, 61] with K dimensions. This design is inspired        100 epochs pre-training with ViT-S/16. The output dimen-
from the projection head with a “prototype layer” used in        sionality K is set to 4096 in this experiment. We observe
SwAV [10]. We do not apply batch normalizations.                 that DINO training fails without the l2-normalization bot-
                                                                 tleneck when increasing the depth of the projection head.
BN-free system. Unlike standard convnets, ViT architec-          L2-normalization bottleneck stabilizes the training of DINO
tures do not use batch normalizations (BN) by default. There-    with deep projection head. We observe that increasing the
                                                                 depth of the projection head improves accuracy. Our default
   ViT-S, 100 epochs      heads w/o BN       heads w/ BN
                                                                 is to use a total of 4 linear layers: 3 are in the MLP and one
   k-NN top-1                  69.7             68.6             is after the l2 bottleneck.
fore, when applying DINO to ViT we do not use any BN also
in the projection heads. In this table we evaluate the impact    Output dimension. In this table, we evaluate the effect
of adding BN in the heads. We observe that adding BN in          of varying the output dimensionality K. We observe that a
the projection heads has little impact, showing that BN is not
                                                                  K                                1024         4096     16384                       65536         262144
important in our framework. Overall, when applying DINO
to ViT, we do not use any BN anywhere, making the system          k-NN top-1                       67.8         69.3      69.2                        69.7            69.1
entirely BN-free. This is a great advantage of DINO + ViT to
                                                                 large output dimensionality improves the performance. We
work at state-of-the-art performance without requiring any
                                                                 note that the use of l2-normalization bottleneck permits to
BN. Indeed, training with BN typically slows down trainings
                                                                 use a large output dimension with a moderate increase in the
considerably, especially when these BN modules need to be
                                                                 total number of parameters. Our default is to use K equals
synchronized across processes [33, 10, 9, 30].
                                                                 to 65536 and d = 256 for the bottleneck.

L2-normalization bottleneck in projection head. We il-
lustrate the design of the projection head with or without l2-   GELU activations. By default, the activations used in ViT
normalization bottleneck in Fig. 9. We evaluate the accuracy     are gaussian error linear units (GELU). Therefore, for consis-
 # proj. head linear layers     1      2       3        4            ViT-S, 100 epochs                        heads w/ GELU                           heads w/ ReLU
 w/ l2-norm bottleneck         –      62.2    68.0     69.3          k-NN top-1                                        69.7                                     68.9
 w/o l2-norm bottleneck       61.6    62.9    0.1      0.1
                                                                 tency within the architecture, we choose to use GELU also
of DINO models trained with or without l2-normalization          in the projection head. We evaluate the effect of using ReLU
bottleneck and we vary the number of linear layers in the        instead of GELU in this table and observe that changing the
projection head. With l2 bottleneck, the total number of         activation unit to ReLU has relatively little impact.
D. Additional Ablations                                                                   60




                                                                                  val acc@1
                                                                                          55
   We have detailed in the main paper that the combination                                50              Student
of centering and sharpening is important to avoid collapse in
                                                                                          45              Teacher
DINO. We ablate the hyperparameters for these two opera-
                                                                                          400                       100
tions in the following. We also study the impact of training
                                                                                                     epochs
length and some design choices for the ViT networks.

Online centering. We study the impact of the smoothing             usually produces a better model than the individual models
parameters in the update rule for the center c used in the         from each iteration [51]. By aiming a target obtained with a
output of the teacher network. The convergence is robust           teacher better than the student, the student’s representations
       m               0      0.9    0.99 0.999                    improve. Consequently, the teacher also improves since it is
                                                                   built directly from the student weights.
       k-NN top-1      69.1      69.7      69.4       0.1
to a wide range of smoothing, and the model only collapses         Self-attention maps from supervised versus self-
when the update is too slow, i.e., m = 0.999.                      supervised learning. We evaluate the masks obtained
                                                                   by thresholding the self-attention maps to keep 80% of
Sharpening. We enforce sharp targets by tuning the                 the mass. We compare the Jaccard similarity between the
teacher softmax temperature parameter τt . In this table,
we observe that a temperature lower than 0.06 is required to                        ViT-S/16 weights
avoid collapse. When the temperature is higher than 0.06,                           Random weights              22.0
τt             0 0.02 0.04 0.06 0.08 0.04 → 0.07                                    Supervised                  27.3
k-NN top-1 43.9 66.7 69.6 68.7                 0.1          69.7                    DINO                        45.9
                                                                                    DINO w/o multicrop          45.1
the training loss consistently converges to ln(K). However,                         MoCo-v2                     46.3
we have observed that using higher temperature than 0.06                            BYOL                        47.8
does not collapse if we start the training from a smaller value                     SwAV                        46.8
and increase it during the first epochs. In practice, we use
a linear warm-up for τt from 0.04 to 0.07 during the first         ground truth and these masks on the validation images of
30 epochs of training. Finally, note that τ → 0 (extreme           PASCAL VOC12 dataset for different ViT-S trained with
sharpening) correspond to the argmax operation and leads           different frameworks. The properties that self-attention
to one-hot hard distributions.                                     maps from ViT explicitly contain the scene layout and, in
                                                                   particular, object boundaries is observed across different
Longer training. We observe in this table that longer train-       self-supervised methods.
ing improves the performance of DINO applied to ViT-Small.
 This observation is consistent with self-supervised results
                                                                   Impact of the number of heads in ViT-S. We study the
        DINO ViT-S 100-ep 300-ep 800-ep                            impact of the number of heads in ViT-S on the accuracy and
        k-NN top-1        70.9          72.8         74.5          throughput (images processed per second at inference time
                                                                   on a singe V100 GPU). We find that increasing the number
obtained with convolutional architectures [12]. We note that
in our experiments with BYOL on ViT-S, training longer             # heads    dim        dim/head      # params           im/sec   k-NN
than 300 epochs has been leading to worse performance com-         6          384               64        21              1007     72.8
pare our 300 epochs run. For this reason we report BYOL            8          384               48        21              971      73.1
for 300 epochs in Tab. 2 while SwAV, MoCo-v2 and DINO              12         384               32        21              927      73.7
are trained for 800 epochs.                                        16         384               24        21              860      73.8
                                                                   of heads improves the performance, at the cost of a slighlty
The teacher outperforms the student. We have shown
                                                                   worse throughput. In our paper, all experiments are run with
in Fig. 6 that the momentum teacher outperforms the student
                                                                   the default model DeiT-S [69], i.e. with 6 heads only.
with ViT and we show in this Figure that it is also the case
with ResNet-50. The fact that the teacher continually out-
                                                                   E. Multi-crop
performs the student further encourages the interpretation of
DINO as a form of Mean Teacher [65] self-distillation. In-           In this Appendix, we study a core component of DINO:
deed, as motivated in Tarvainen et al. [65], weight averaging      multi-crop training [10].
                                                                                            65




                                                                                k-nn val top-1
Range of scales in multi-crop. For generating the dif-
                                                                                            60
ferent views, we use the RandomResizedCrop method
                                                                                            55
from torchvision.transforms module in PyTorch.                                                            w/o mc
                                                                                            50
We sample two global views with scale range (s, 1) before                                                 w/ mc
 (0.05, s), (s, 1), s:   0.08     0.16     0.24   0.32   0.48
                                                                                            45
                                                                                                 0   100 200       300
 k-NN top-1              65.6     68.0     69.7   69.8   69.5                                          epochs
resizing them to 2242 and 6 local views with scale sampled
in the range (0.05, s) resized to 962 pixels. Note that we       amount of training. We have performed learning rate, weight
arbitrarily choose to have non-overlapping scaling range for     decay, multi-crop parameters sweeps for this setting and
the global and local views following the original design of      systematically observe the same pattern. More precisely, we
SwAV. However, the ranges could definitely be overlapping        experiment with {1e−5 , 3e−5 , 1e−4 , 3e−4 , 1e−3 , 3e−3 } for
and experimenting with finer hyperparameters search could        learning rate base values, with {0.02, 0.05, 0.1} for weight
lead to a more optimal setting. In this table, we vary the pa-   decay and with different number of small crops: {2, 4, 6}.
rameter s that controls the range of scales used in multi-crop   All our runs are performed with synchronized batch normal-
and find the optimum to be around 0.3 in our experiments.        izations in the heads. When using a low learning rate, we
We note that this is higher than the parameter used in SwAV      did not observe the performance break point, i.e. the trans-
which is of 0.14.                                                fer performance was improving continually during training,
                                                                 but the overall accuracy was low. We have tried a run with
                                                                 multi-crop training on ResNet-50 where we also observe
Multi-crop in different self-supervised frameworks.              the same behavior. Since integrating multi-crop training to
We compare different recent self-supervised learning frame-      BYOL is not the focus of this study we did not push that
works, namely MoCo-v2 [15], BYOL [30] and SwAV [10]              direction further. However, we believe this is worth investi-
with ViT-S/16 architecture. For fair comparisons, all models     gating why multi-crop does not combine well with BYOL in
  crops            2 × 2242              2 × 2242 + 6 × 962      our experiments and leave this for future work.
  eval          k-NN     linear          k-NN       linear       F. Evaluation Protocols
  BYOL          66.6      71.4           59.8        64.8        F.1   k-NN classification
  SwAV          60.5      68.5           64.7        71.8
  MoCo-v2       62.0      71.6           65.4        73.4        Following the setting of Wu et al. [73], we evaluate the qual-
  DINO          67.9      72.5           72.7        75.9        ity of features with a simple weighted k Nearest Neighbor
                                                                 classifier. We freeze the pretrained model to compute and
                                                                 store the features of the training data of the downstream task.
are pretrained either with two 2242 crops or with multi-         To classify a test image x, we compute its representation
crop [10] training, i.e. two 2242 crops and six 962 crops for    and compare it against all stored training features T . The
each image. We report k-NN and linear probing evaluations        representation of an image is given by the output [CLS]
after 300 epochs of training. Multi-crop does not benefit all    token: it has dimensionality d = 384 for ViT-S and d = 768
frameworks equally, which has been ignored in benchmarks         for ViT-B. The top k NN (denoted Nk ) are used to make a
considering only the two crops setting [16]. The effective-      prediction via weighted    voting. Specifically, the class c gets
ness of multi-crop depends on the considered framework,                            P
                                                                 a total weight of i∈Nk αi 1ci =c , where αi is a contribution
which positions multi-crop as a core component of a model        weight. We use αi = exp(Ti x/τ ) with τ equals to 0.07 as
and not a simple “add-ons” that will boost any framework the     in [73] which we do not tune. We evaluate different values
same way. Without multi-crop, DINO has better accuracy           for k and find that k = 20 is consistently leading to the best
than other frameworks, though by a moderate margin (1%).         accuracy across our runs. This evaluation protocol does not
Remarkably, DINO benefits the most from multi-crop train-        require hyperparameter tuning, nor data augmentation and
ing (+3.4% in linear eval). Interestingly, we also observe       can be run with only one pass over the downstream dataset.
that the ranking of the frameworks depends on the evaluation
protocol considered.
                                                                 F.2   Linear classification
Training BYOL with multi-crop. When applying multi-              Following common practice in self-supervised learning, we
crop to BYOL with ViT-S, we observe the transfer perfor-         evaluate the representation quality with a linear classifier.
mance is higher than the baseline without multi-crop for         The projection head is removed, and we train a supervised
the first training epochs. However, the transfer performance     linear classifier on top of frozen features. This linear clas-
growth rate is slowing down and declines after a certain         sifier is trained with SGD and a batch size of 1024 during
100 epochs on ImageNet. We do not apply weight decay.
For each model, we sweep the learning rate value. Dur-
ing training, we apply only random resizes crops (with de-
fault parameters from PyTorch RandomResizedCrop)
and horizontal flips as data augmentation. We report central-
crop top-1 accuracy. When evaluating convnets, the common
practice is to perform global average pooling on the final
feature map before the linear classifier. In the following, we
describe how we adapt this design when evaluating ViTs.

ViT-S representations for linear eval. Following the
feature-based evaluations in BERT [18], we concatenate
the [CLS] tokens from the l last layers. We experiment
    concatenate l last layers          1    2      4      6
    representation dim             384     768    1536   2304
    ViT-S/16 linear eval           76.1    76.6   77.0   77.0
with the concatenation of a different number l of layers and
similarly to [18] we find l = 4 to be optimal.

ViT-B representations for linear eval. With ViT-B we
did not find that concatenating the representations from the
last l layers to provide any performance gain, and consider
the final layer only (l = 1). In this setting, we adapt the
 pooling strategy          [CLS] tok. concatenate [CLS] tok.
                              only    and avgpooled patch tok.
 representation dim             768               1536
 ViT-B/16 linear eval           78.0              78.2
pipeline used in convnets with global average pooling on the
output patch tokens. We concatenate these pooled features
to the final [CLS] output token.

G. Self-Attention Visualizations
   We provide more self-attention visualizations in Fig. 8
and in Fig. 10. The images are randomly selected from
COCO validation set, and are not used during training of
DINO. In Fig. 8, we show the self-attention from the last
layer of a DINO ViT-S/8 for several reference points.
H. Class Representation
   As a final visualization, we propose to look at the distribu-
tion of ImageNet concepts in the feature space from DINO.
We represent each ImageNet class with the average feature
vector for its validation images. We reduce the dimension
of these features to 30 with PCA, and run t-SNE with a
perplexity of 20, a learning rate of 200 for 5000 iterations.
We present the resulting class embeddings in Fig. 11. Our
model recovers structures between classes: similar animal
species are grouped together, forming coherent clusters of
birds (top) or dogs, and especially terriers (far right).
                     DINO                        Supervised                                 DINO                       Supervised




Figure 10: Self-attention heads from the last layer. We look at the attention map when using the [CLS] token as a query for the different
heads in the last layer. Note that the [CLS] token is not attached to any label or supervision.
                                                                                                                                  chickadee goldfinch
                                                                                                                                             junco
                                                                                                                                         sulphur-crested   bee eater lorikeet   African grey
                                                                                                                                                   bulbul cockatoo
                                                                                                                                                  jay        jacamar macaw
                                                                                                                                                                               toucan ruddy turnstonered-backed sandpiper
                                                                                                                                       brambling hummingbird
                                                                                                                                                           robin kinghornbill
                                                                                                                                                                         penguin                  dowitcher
                                                                                                                          indigo bunting                             kite European   redshank
                                                                                                                                       house finch coucalmagpie                 peacock gallinule
                                                                                                                                                                                         drake American coot    red-breasted merganser
                                                                                                                                               bald eagle                cock
                                                                                                                                                                            hen
                                                                                                                                          black grouse               vulture ostrichgoose
                                                                                                                                                         oystercatcher
                                                                                                                                                                                                      albatross black swan
                                                                                                                                                                           bustard
                                                                                                                                                       water ouzel ptarmigan                     pelican
                                                                                                                                                                     quail      blackcrane                   flamingo
                                                                                                                                                                                       stork little blueAmerican
                                                                                                                                                               partridge
                                                                                                                                                   prairie chicken                                       heron egret
                                                                                                                                     great grey owl                       bittern limpkin          spoonbill
                                                                                                                                                                   ruffed grouse         white stork




                                                                                                                                                                                                                                                                                 orangutan
                                                                                                                                                                                                                                                                     baboon
                                                                                                                                                                                                                                                        macaque                   gorilla         chimpanzee
                                                                                    garter snake                                                                                                                                                                    patas gibbon         siamang
                                                                          sidewinder            king snake                                                                                                                                 proboscis monkey                 langur
                                                                                                                                                                                                                                    squirrel monkey               guenon                  spider monkey
                                         horned viper
                                                        hognose snake                      night snake ringneck snake                                                                                                                               three-toed sloth titi capuchin                        howler monkey
                                                            diamondback rock  python                     thunder   snake                                                                                                                                                    marmoset          colobus
                                         boa constrictor                               Indian cobra                                                                                                                                                                                   indri cat
                                                                                                                                                                                                                                                                                Madagascar
                                                               water snake  green mamba              green snake                                                                                                                                                       koala                        sloth  bear
                                                                                               vine snake                                                                                                                                          Americanlesser         bear
                                                                                                                                                                                                                                                                 blackpanda
                                                                                                                                                                                                                                                   echidna                            giant panda                                                                                        Border terrier
                                                                                 green lizard                                                                                                                                                                  beaver badger    polecat     skunk brown bear                                                                affenpinscher
                                                                                                                                                                                                                                                                                                                                                                giant schnauzer
                                                                                                                                                                                                                                                                                                                                                                                                     miniature schnauzer
                                                                                                                                                                                                                                                                                                                                                                                           Scotch terrier         Norwich terrier
                 European fire salamander                       alligator   lizard  whiptail     American    chameleon                                                                                                                               porcupine        weasel       black-footed     ferret                                Bouvier des Flandres Irish water spaniel                         standard schnauzer
                                           spotted salamander                                   tree  frog                                                                                                                               mongoose                otter       mink         guinea pig           curly-coated     retriever
                                                            common newt eft agama           African chameleon                                                                                                                                          marmotmeerkat wombat                      Angora                                schipperke          Kerry blue terrier                Irish terrier      Australian terrier
                                                                                                                                                                                                                                                                                    hamster
                                                                                                                                                                                                                                                                              fox squirrel                           Tibetan   mastiff        groenendael                                Airedale        cairn         silky terrier
                                                                             gecko frog frilled lizard common iguana
                                                                  banded tailed                                                                                                                                                                                                                                                          retrieverNewfoundland
                                                                                                                                                                                                                                                  wood rabbit wallaby                          Persian cat ice bear flat-coated      soft-coated     wheaten terrier Afghan    IrishLakeland  terrier terrier
                                                                                                                                                                                                                                                                                                                                                                                             Yorkshire
                                                                                                                                                                                                                                                                                                                                                                                      wolfhound
                                                                                                                                                                                                                                                                                                                                                                                      hound otterhound
                                                                                                                                                                                                                                                                                                                                                                                                             Norfolk terrier
                                                                                                                                                                                                                                                                                                                                                                                                                  Tibetan terrier
                                              American alligator                    bullfrog                  Komodo dragon                                                                                                                                      hareSiamese cat                         Arctic fox keeshond    Leonberg Sussex wire-haired
                                                                                                                                                                                                                                                                                                                                                         spanielScottish  deerhound
                                                                                                                                                                                                                                                                                                                                                                       Gordon                               briard Shih-Tzu
                                                                     box turtle           African    crocodile                                                                                                         sea lion                                                       Egyptian     cat                                      chow                      fox terriersetter Dandie Dinmont
                                                                                                                                                                                                                                                                                                                                                                                                     komondor Lhasa
                                                                                                                                                                                                                                                                                           grey  fox                                           Samoyed                 Old English    sheepdog
                                                                     terrapin
                                                                                mud turtle
                                                                                                  Gila monster
                                                                                                                                                                                                                               hippopotamus
                                                                                                                                                                                                                      triceratops            hog              hyenacougar
                                                                                                                                                                                                                                                                             tiger cat
                                                                                                                                                                                                                                                                                      tabby          coyote whitetimber wolf
                                                                                                                                                                                                                                                                                                                                wolf Pekinese
                                                                                                                                                                                                                                                                                                                                                    Irish setter
                                                                                                                                                                                                                                                                                                                                                   golden    retriever
                                                                                                                                                                                                                                                                                                                                                               kuvasz
                                                                                                                                                                                                                                                                                                                                                                      cocker spaniel
                                                                                                                                                                                                                                                                                                                                                                                     Bedlington terrier
                                                                                                                                                                                                                                                                                                                                                                                                             Sealyham
                                                                                                                                                                                                                                                                                                                                                                                                     West Highland
                                                                                                                                                                                                                                                                                                                                                                                                                     Maltese dog
                                                                                                                                                                                                                                                                                                                                                                                                                        terrier
                                                                                                                                                                                                                                                                                                                                                                                                                      white  terrier
                                                                                                                                                                                                                                                                  dog lynx cheetahred foxdhole red wolf Pomeranian                                      borzoi
          tiger beetle
                      weevil                     black and gold garden spider
                                                                                        armadillo
                                                                                                   axolotl                                                                                                                          warthogAfrican wild
                                                                                                                                                                                                                                                      hunting
                                                                                                                                                                                                                              tusker bison ram llama lion
                                                                                                                                                                                                                                                         boar                                                                      Great Pyrenees
                                                                                                                                                                                                                                                                                                           Shetland sheepdogmalamuteSaint          collie English setter
                                                                                                                                                                                                                                                                                                                                                                       clumber
                                                                                                                                                                                                                                                                                                                                                                                  miniature poodle          toy poodle
                                                                                                                                                                                                                                                                                                                                                                                                   standard poodle
                 cricket
ground beetlebeetle               garden spider                                                                                                                                                 African elephant                                                           tiger Norwegian     kit fox                                                 Bernard
                                                                                                                                                                                                                                                                                                                                                     Border    collie         Welsh springer spaniel
long-horned             black widow       barn spider leatherbackloggerhead     turtle        platypus      tench
                                                                                                                        barracouta                                                                               Indian   elephant                     ibex     zebra           snow leopard         elkhound      dingo                 papillon
                                                                                                                                                                                                                                                                                                                            Eskimo dog Japanese spaniel Blenheim spaniel
grasshopper cicada ant                             wolf spider dung   beetle           eel             coho                                                                                                                    water   buffalo       Arabian    camel jaguarleopard        German     shepherd
                                                                                                                                                                                                                                                                                                             malinois                                                                Brittany  spaniel
            mantis       fly tick tarantulacentipede                                              gar          sturgeon                                                                                                                        bighorn                                                             Siberian husky
     leafhopper rhinoceros     leaf beetle isopod spiny lobstersea snakedugong tiger shark
                    ladybugbeetle                                                                                           great white shark                                                                                      oxcart ox
                                                                                                                                                                                                                                             sorrel     impala gazelle                                                           PembrokeCardigan              English springer
                                                                                                                                                                                                                                                                                                                                                  Bernese mountain dog
walking stick                       cockroach rockseacrab                 electric puffer    stingray
           lacewing                                             cucumber            brain coral scuba hammerhead
                                                                                    ray                                                                                                                                      horse cart hartebeest                                                                              dogsled beagle            bassethound Appenzeller
harvestman dragonflyspider web            hermit crab
                                    scorpion          chiton     starfish
                                                         trilobite flatworm rock beauty         goldfish
                                                                                                               diver                                                                                                                                                                                                                   Saluki
                                                                                                                                                                                                                                                                                                                  English foxhoundwhippet              Walker
      damselfly             bee fiddler crabcrayfish              honeycomb coral reef jellyfish             snorkel                                                                                                                                                                                                       Ibizan houndbasenjidalmatian               EntleBucher
                                             American                           sea slug                                                                                                                                                                                                                                                                     Greater Swiss Mountain dog
                Dungeness crab                  king crablobster conch             sea sea
                                                                                        urchin
                                                                                                anemone fish
                                                                                            anemone                                                                                                                                                                                                                     muzzle
                                                                                                                                                                                                                                                                                                            Chihuahua Bostontoy
                                                                                                                                                                                                                                                                                                                                                          bluetick
                                                                                                                                                                                                                                                                                                                                                         Italian greyhound German short-haired pointer
                                                           chambered       nautilus
                                                            slug snail lionfish                                                                                                                                                                                                                                                        bullterrier
                                                                                                                                                                                                                                                                                                                                                Dobermankelpieminiature  pinscher
                                            stinkhorn                                                                                                                                                                                                                          Staffordshire bullterrier French bulldog                      boxer                Rottweiler
                            admiral                                                                                                                                                                                                                                                                      Brabancon griffon                pug       Great Dane               black-and-tan coonhound
                                                        bolete agaric                                                                                                                                                                                                                                                    Mexican hairless redbone
                  lycaenid monarch earthstar                      mushroom                                                                                                                                                                                                                                                                             American Staffordshire terrier
cabbage butterfly                    cardoon coral fungus                           gyromitra                                                                                                                                                                                                                                   bull mastiff              bloodhound                        Labrador retriever
                            ringletdaisy      acorn                 hen-of-the-woods                                                                                                                                                                                                                                                           vizsla               Chesapeake Bay retriever
         sulphur butterfly                hip                jackfruit                                                                                                                                                                                                                                              Rhodesian     ridgeback          Weimaraner
              yellow ladys slipper                   buckeyepineapple
                                              artichoke
                                     custard apple head cabbage     pot
                                                broccoli                     cauliflower
                                strawberry fig corn ear
                         bell pepper orange pomegranate zucchini
                                                                      cucumber
                  Granny Smith lemon                acorn
                                                       banana squash
                               spaghetti squash
                                                      butternut squash
                                              pretzel
                                      hotdog French loaf
                    cheeseburger              bagel dough                                                                                      dishrag                                         wig
                                     burrito potpie                        rotisserie                                                                   mitten                  mortarboard brassiere
                          meat loaf                     ice cream                       butcher shop                                               wool stole cardigan Windsor tie
                                      pizza plate    mashed potato  chocolate sauce            grocery store                       handkerchiefponcho              sweatshirt     bow tie
                         carbonara          guacamole                    restaurant                                                                          bonnet       jersey                        lab coat                        maillot
                                     soup bowl              hot pot                    bakery                          Christmas stocking pillow velvet                      fur coat abaya                                                     bikini bathing cap
                                                                   frying pan                                                                                        overskirt gown suit
                           consomme trifle                   wok             Dutch oven                                        bath towel
                                                                                                                                            teddy bib vestmentapron hoopskirt cloak
                                                                                                                                                           sock                                      coat gown saxoboe
                                                                                                                                                                                          trenchacademic                                      maillot swimming trunks
                                               Crock Pot                                                                                                        jean              groomminiskirt           French    horn             bassoon
                                                                caldron potters wheel                                                      sleeping bag              pajamakimono                               cornet trombone parallel bars
                                                                                                                                                 diaper  feather    boa           uniform pickelhaube
                                                                                                                                                                       military sarong                               flutecello balance beam horizontal bar
                                                                                                                       jack-o-lantern                                                                         bearskin                                                           ping-pong ball
                                                                                                                                           plastic bag
                                                                                                                                                        shower cap
                                                                                                                                                                   neck bracecowboy      bulletproof       panpipe
                                                                                                                                                                                                         vest
                                                                                                                                                                                                      accordion                   banjo
                                                                                                                                                                                                                      violin acoustic     guitarvolleyball racket ballplayer
                                                                                                                                                                                           hat carousel         harpelectric
                                                         espresso                                                                                       ice lolly        mask sombrero                                 marimbaguitar                basketball            rugby ball
                                                                                                                                                                                                                                                                  baseball soccer ballgolf ball
                                                                     mixing    bowl                nematode                         chain mail                   pinwheel cowboy boot steel               rifledrum
                                                                                                                                                                                                                                 drum
                                                                                                                                                                                                                                     football helmet
                                                     eggnog                       candle                                   bolo tie           nail hatchet                    ki mask assault rifle                                                      puck                   tennis ball
                                   measuring cup                cup                   piggy bank strainer spindle necklace            hook knot backpack        sunglasses                          breastplate torchstage                                    croquet ball
                                                                 coffeevase
                                    beer glass beaker pitcher whiskey
                                                                          mug                    Petri dish maraca                                                            belt cuirass
                                                                                                                                                                       seat sunglass                           bubble
                                              red wine goblet                teapot jugmortar            ladle
                                                                                                                                            chain
                                                                                                                                   safety pin clogLoafer mailbag oxygen
                                                                                                             traybottlecaphair slide                                               gasmask                crutch bowumbrella unicycle
                                                                                                                                                                                                                                                ski
                                                                                   bucket                   matchstick ocarina pick            running shoe harmonica                     mask                   swing           maypole          mountain      bike
                                                     coffeepot          water   jug      wooden     spoon        quill                   sandal                                                reel plunger stretcher
                                                                                                                                                                                       binoculars                                                                      snowmobile
                         beer bottlecocktail    shaker                             saltshaker spatula
                                                                      soap dispenser                                     paintbrushbuckle kneestethoscope
                                                                                                                                                       pad                microphone  punching bag                                            bicycle-built-for-two
                                                                                                                                                                                                                                                       bobsled
                                      pop bottle wine bottle           nipple            hourglass cleaver
                                                                                   thimble                         syringe lipstick padlock                   hand blower tripod                                broom           tricycle
                                                                                                                                       Band Aid                                                        pool table         shovel            moped
                                               pill bottlelotion           water bottle screwdriver         drumstick face powder            pencil   boxpurse
                                                                                                                                                  wallet              power drill
                                                                                                                                                                                   vacuumdumbbell chain sawjinrikisha motor go-kart
                                                                sunscreen mousetrap    pencil     hammer loupelighter
                                                                                                sharpener                               envelope       packet            book    jacket   barbell                                                    scooter
                                                   perfume                                                 plane
                                                                                                             letter opener pen  rubber   eraser                  comic book                                                        lawn mower
                                                                           hair spray                holster scabbardfountainwhistle ballpoint   menu
                                                                                                                                                    crossword      puzzle
                                                                                                                                                                        jigsaw    puzzle
                                                                                                                                                                                swab                                       barrow
                                                                                                                        can opener rulebinderabacus                     doormat shopping basketmilk can               apiary plow cannon                           cliff              grey whale
                                                                                                             corkscrew              slide rule web site prayer rughamper                                                                                              promontory                     killer whale
                                                                                                                                                                                                                                                                                                         paddle
                                                                                                                           screw                                                                       barrel                    lumbermill             cliff dwelling valley
                                                                                                   revolver                                                                                  rain barrel ashcan crate                           stone wall             alp seashore sandbar                       canoe
                                                                                                                                           chime       bathtub                                                                         worm    fence            megalith                lakeside
                                                                                                                                   shield                        tub          table lamp                                          park bench mountain              tent      volcano         breakwater
                                                                                                                                                 washbasin          lampshade               bassinet                      picket   fence                      hay     geyser damwreck schooner yawl
                                                                                              analog clock wall clock            gong coil                toilet tissue         cradleshower curtain upright     greenhouse                      thatch
                                                                                                                                                                                                                                                              rapeseed paddlewheel                       gondola catamaran    trimaran
                                                                                                         barometer          electric fan spotlight   toilet  seat   paper towel              grand    piano         chainlink    fence
                                                                                                                                                                                                                                       patio yurt barn
                                                                                                                                                                                                                                                      maze          boathouse               pier      dock    pirate
                                                                                                                                                                                                                                    birdhousesuspension                               steel arch    bridge          lifeboat speedboat
                                                                                                  odometer magnetic     oil filter waffledisk
                                                                                                                               compasscrash ironbrakescalecarton    studiochest
                                                                                                                                                                                  quilt crib
                                                                                                                                                                            couchmosquito           window screen                          tile roof       polebridge            beacon
                                                                                                                                                                                                                                                                   solar dishdrilling         crane         fireboat
                                                                                                         stopwatch                               helmet        radiator
                                                                                                                                                            four-poster                          netscreen theater curtain
                                                                                                                                                                                              fire                                                 totem    pole         fountain        platform
                                                                                   combination lock                                            iron plate rack                                                                          brass         radio telescope flagpole submarine                        liner container ship
                                                                                                       digital watch dial     telephone
                                                                                                                          espresso         sewing machine
                                                                                                                                       maker
                                                                                                                                        toaster space heater stove
                                                                                                                                                                       window shade
                                                                                                                                                                             wardrobe
                                                                                                                                                                                        shoji bannister manhole cover
                                                                                                                                                                                                                 prison
                                                                                                                                                                                                                                               sundial
                                                                                                                                                                                                                                                        waterplanetarium
                                                                                                                                                                                                                                                                 tower balloonprojectile      airshipaircraft carrier
                                                                                                                  lens cap                                                                                  rocking    chair           pedestal obelisk
                                                                                                       reflex camera joystick switch                       washer     barber chair
                                                                                                                                                               dishwasher           chest slidingfolding      chairguillotine     monasterybell cote                parachute missilewarplane airliner
                                                                               computer keyboard                     space    bar typewriter       microwave medicine
                                                                                                                                                keyboard                   chiffonier
                                                                                                                                                                                    dining   table    door                    throne         church  castle  stupa
                                                                                                                                                                                                                                                        palace
                                                                                                                                                                                                                                                                viaduct                            wing
                                                                                                                                                                                            china   cabinet shopping cart altar                                                    space shuttle
                                                                                                      carpenters kit           modemloudspeaker            refrigeratorfile bookcase
                                                                                                                                                    television                                  turnstile
                                                                                                                                                                                                 library barbershop                      vault                   mosque                                  bullet train
                                                                                               remote control hard disccassettedigital clock      mouse        home theater
                                                                                                                                                             screen                                                               organ dome
                                                                           hand-held computer Polaroid cameraiPod                                      monitor                 shoe shop tobaccobookshop
                                                                                                 cellular telephone
                                                                                                                                        projector
                                                                                                                                             notebook
                                                                                                                                                   laptop entertainment center          toyshop slotshop scoreboard traffic light triumphal arch
                                                                                                                  cassette player     tape  player   desktopdesk computer       confectionery                   cinema      street sign                                                                       tractor
                                                                                                                                  radio CD player   printer                            vendinggas      pump
                                                                                                                                                                                                   machine                                                                                         thresher tank
                                                                                                                  oscilloscope safe                                               pay-phone                       mailbox
                                                                                                                                                           photocopier
                                                                                                                                                                          cash machine                                    parking meter                                                      harvester half           track
                                                                                                                                                                                                                                                                    steam locomotive                   amphibian                 Model T
                                                                                                                                                                                                                                                                                                  forklift snowplowgolfcart
                                                                                                                                                                                                                                                          electric locomotive freight car trailer truck jeep racer carcar                       mirror
                                                                                                                                                                                                                                                                                                                                            wheel
                                                                                                                                                                                                                                                                                  passenger car                    tow  cab
                                                                                                                                                                                                                                                                                                                         truck
                                                                                                                                                                                                                                                                                                                             sports  car
                                                                                                                                                                                                                                                                    mobile home garbage truckmoving van beachgrille               wagon
                                                                                                                                                                                                                                                                                               fire engine
                                                                                                                                                                                                                                                                                      school bus                limousine minivanpickup      convertible
                                                                                                                                                                                                                                                                                 streetcar trolleybus                police van
                                                                                                                                                                                                                                                        recreational vehicle                              minibus
                                                                                                                                                                                                                                                                                                                    ambulance




Figure 11: t-SNE visualization of ImageNet classes as represented using DINO. For each class, we obtain the embedding by taking the
average feature for all images of that class in the validation set.
